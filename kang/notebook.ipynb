{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.0 LLMs and Chat Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms.openai import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(model_name=\"gpt-3.5-turbo-1106\")\n",
    "chat = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = llm.predict(\"How many planets are there?\")\n",
    "b = llm.predict(\"How many planets are there?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('There are eight recognized planets in our solar system: Mercury, Venus, Earth, Mars, Jupiter, Saturn, Uranus, and Neptune. However, there are ongoing debates and explorations for the possible existence of a ninth planet in the outer solar system.',\n",
       " 'There are eight recognized planets in our solar system: Mercury, Venus, Earth, Mars, Jupiter, Saturn, Uranus, and Neptune.')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a, b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Predict Messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import HumanMessage, AIMessage, SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='멕시코와 태국 사이의 거리는 약 14,000km 정도 되요. 제 이름은 딩고에요!')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    SystemMessage(content='you are a geograph expert. and you only reply in Korea.'),\n",
    "    AIMessage(content='와우! 제 이름은 딩고에요!'),\n",
    "    HumanMessage(content=\"맥시코와 태국 사이의 거리는 얼마인가. 그리고 너의 이름은 무엇이니?\"),\n",
    "]\n",
    "\n",
    "chat.predict_messages(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Prompt Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.2.1 PromptTemplate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'what is the distance between Mexico and Thailand'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template = PromptTemplate.from_template(\"what is the distance between {country_a} and {country_b}\",)\n",
    "\n",
    "template.format(country_a=\"Mexico\", country_b=\"Thailand\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_variables': ['country_a', 'country_b'],\n",
       " 'input_types': {},\n",
       " 'output_parser': None,\n",
       " 'partial_variables': {},\n",
       " 'template': 'what is the distance between {country_a} and {country_b}',\n",
       " 'template_format': 'f-string',\n",
       " 'validate_template': False}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The distance between Mexico and Thailand is approximately 9,500 miles (15,300 kilometers) when measured in a straight line.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = template.format(country_a=\"Mexico\", country_b=\"Thailand\")\n",
    "\n",
    "chat = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "chat.predict(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.2.2 ChatPromptTemplate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_variables': ['country_a', 'country_b', 'language', 'name'],\n",
       " 'input_types': {},\n",
       " 'output_parser': None,\n",
       " 'partial_variables': {},\n",
       " 'messages': [SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['language'], template='you are a geograph expert. and you only reply in {language}.')),\n",
       "  AIMessagePromptTemplate(prompt=PromptTemplate(input_variables=['name'], template='와우! 제 이름은 {name}에요!')),\n",
       "  HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['country_a', 'country_b'], template='{country_a}와 {country_b} 사이의 거리는 얼마인가. 그리고 너의 이름은 무엇이니?'))],\n",
       " 'validate_template': False}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"you are a geograph expert. and you only reply in {language}.\",),\n",
    "    (\"ai\", \"와우! 제 이름은 {name}에요!\",),\n",
    "    (\"human\", \"{country_a}와 {country_b} 사이의 거리는 얼마인가. 그리고 너의 이름은 무엇이니?\",),],\n",
    ")\n",
    "\n",
    "vars(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='you are a geograph expert. and you only reply in Korea.'), AIMessage(content='와우! 제 이름은 딩고에요!'), HumanMessage(content='Mexico와 Thailand 사이의 거리는 얼마인가. 그리고 너의 이름은 무엇이니?')]\n"
     ]
    }
   ],
   "source": [
    "prompt = messages.format_messages(\n",
    "    language=\"Korea\",\n",
    "    name=\"딩고\",\n",
    "    country_a=\"Mexico\",\n",
    "    country_b=\"Thailand\",\n",
    ")\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='멕시코와 태국 사이의 거리는 약 15,000km 정도 되요. 제 이름은 딩고에요!')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.predict_messages(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 OutputParser and LCEL\n",
    "\n",
    "**3.3.1 OutputParser**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello', 'how', 'are', 'you?']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.schema import BaseOutputParser\n",
    "\n",
    "class CommaOutputParser(BaseOutputParser):\n",
    "\n",
    "    def parse(self, text):\n",
    "        items =  text.strip().split(\",\")\n",
    "        return list(map(str.strip, items))\n",
    "\n",
    "p = CommaOutputParser()\n",
    "\n",
    "p.parse(\"Hello, how, are, you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='You are a list generating machine. Everything you ar asked will be answered with a comma seperated list of max 10 in lowercase. Do Not reply with anything else.'), HumanMessage(content='What are the colors?')]\n"
     ]
    }
   ],
   "source": [
    "template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a list generating machine. Everything you ar asked will be answered with a comma seperated list of max {max_items} in lowercase. Do Not reply with anything else.\"),\n",
    "    (\"human\", \"{question}\"),\n",
    "])\n",
    "\n",
    "prompt = template.format_messages(\n",
    "    max_items = 10,\n",
    "    question=\"What are the colors?\"\n",
    ")\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='red, blue, green, yellow, orange, purple, pink, black, white, brown')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.predict_messages(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['red',\n",
       " 'blue',\n",
       " 'green',\n",
       " 'yellow',\n",
       " 'orange',\n",
       " 'purple',\n",
       " 'pink',\n",
       " 'black',\n",
       " 'white',\n",
       " 'brown']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = chat.predict_messages(prompt)\n",
    "p = CommaOutputParser()\n",
    "parse_result = p.parse(result.content)\n",
    "parse_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(parse_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.3.2 LCEL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = template | chat | p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars(chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pikachu', 'charmander', 'bulbasaur', 'squirtle', 'jigglypuff']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\n",
    "    \"max_items\": 5,\n",
    "    \"question\": \"What are the pokemons?\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Chaining Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "\n",
    "chat = ChatOpenAI(temperature=0.1, streaming=True, callbacks=[StreamingStdOutCallbackHandler(),],)\n",
    "\n",
    "chef_promt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a world-class international chef. You create easy to follow recipes for any type of cuisine with easy to find ingredients.\"),\n",
    "    (\"human\", \"I wnat to cook {cuisine} food.\"),\n",
    "])\n",
    "\n",
    "chef_chain = chef_promt | chat\n",
    "\n",
    "vars(chef_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "veg_chef_promt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a vegetarian chef specialized on making traditional recipies vegetarian. You find alternative ingredients and explain their preparation. You don't radically modify the recipe. If there is no alternative for a food just say you don't know how to replace it.\"\n",
    "),\n",
    "    (\"human\", \"{recipe}\"),\n",
    "])\n",
    "\n",
    "veg_chain = veg_chef_promt | chat\n",
    "\n",
    "vars(veg_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_chain = {\"recipe\" : chef_chain} | veg_chain\n",
    "\n",
    "vars(final_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Great choice! How about making a classic Korean dish called Bibimbap? It's a delicious and colorful mixed rice bowl that's packed with flavor. Here's a simple recipe for you to try:\n",
      "\n",
      "Ingredients:\n",
      "- 1 cup of cooked white rice\n",
      "- 1 carrot, julienned\n",
      "- 1 zucchini, julienned\n",
      "- 1 cup of spinach\n",
      "- 1 cup of bean sprouts\n",
      "- 4 shiitake mushrooms, sliced\n",
      "- 1/2 pound of beef (you can use ribeye or sirloin), thinly sliced\n",
      "- 4 eggs\n",
      "- Sesame oil\n",
      "- Soy sauce\n",
      "- Gochujang (Korean chili paste)\n",
      "- Sesame seeds\n",
      "- Salt and pepper\n",
      "- Vegetable oil\n",
      "\n",
      "Instructions:\n",
      "1. Marinate the beef: In a bowl, mix the beef slices with 2 tablespoons of soy sauce, 1 tablespoon of sesame oil, and a pinch of black pepper. Let it marinate for at least 15 minutes.\n",
      "2. Cook the rice according to package instructions and set aside.\n",
      "3. In a pan, heat some vegetable oil over medium heat. Stir-fry the carrots, zucchini, and mushrooms separately until they are cooked but still slightly crunchy. Season each with a pinch of salt.\n",
      "4. Blanch the spinach and bean sprouts in boiling water for about 1 minute. Drain and squeeze out excess water. Season each with a pinch of salt and a drizzle of sesame oil.\n",
      "5. In the same pan, cook the marinated beef until browned and cooked through.\n",
      "6. In a separate pan, fry the eggs sunny-side up or however you prefer.\n",
      "7. To assemble the Bibimbap, divide the rice into bowls. Arrange the cooked vegetables and beef on top of the rice. Place a fried egg on top of each bowl.\n",
      "8. Serve with a side of gochujang and sprinkle with sesame seeds.\n",
      "9. Mix everything together before eating to enjoy all the flavors combined.\n",
      "\n",
      "Enjoy your homemade Bibimbap! Feel free to customize it with your favorite vegetables or protein. Let me know if you have any questions or need more Korean recipe ideas.For a vegetarian version of Bibimbap, you can easily substitute the beef with tofu or tempeh. Here's how you can prepare the tofu or tempeh as a replacement for the beef:\n",
      "\n",
      "**Tofu:**\n",
      "1. Use firm or extra-firm tofu for this recipe. Press the tofu to remove excess water by wrapping it in a clean kitchen towel and placing a heavy object on top for about 15-20 minutes.\n",
      "2. Cut the tofu into thin slices or cubes, depending on your preference.\n",
      "3. Marinate the tofu in a mixture of soy sauce, sesame oil, and a pinch of black pepper for at least 15 minutes.\n",
      "4. In a pan, heat some vegetable oil over medium heat and cook the marinated tofu until browned and slightly crispy.\n",
      "\n",
      "**Tempeh:**\n",
      "1. Cut the tempeh into thin slices or cubes.\n",
      "2. Steam the tempeh for about 10 minutes to remove any bitterness.\n",
      "3. Marinate the tempeh in a mixture of soy sauce, sesame oil, and a pinch of black pepper for at least 15 minutes.\n",
      "4. In a pan, heat some vegetable oil over medium heat and cook the marinated tempeh until browned and slightly crispy.\n",
      "\n",
      "Follow the rest of the recipe as instructed, replacing the beef with your prepared tofu or tempeh. Enjoy your vegetarian Bibimbap!"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessageChunk(content=\"For a vegetarian version of Bibimbap, you can easily substitute the beef with tofu or tempeh. Here's how you can prepare the tofu or tempeh as a replacement for the beef:\\n\\n**Tofu:**\\n1. Use firm or extra-firm tofu for this recipe. Press the tofu to remove excess water by wrapping it in a clean kitchen towel and placing a heavy object on top for about 15-20 minutes.\\n2. Cut the tofu into thin slices or cubes, depending on your preference.\\n3. Marinate the tofu in a mixture of soy sauce, sesame oil, and a pinch of black pepper for at least 15 minutes.\\n4. In a pan, heat some vegetable oil over medium heat and cook the marinated tofu until browned and slightly crispy.\\n\\n**Tempeh:**\\n1. Cut the tempeh into thin slices or cubes.\\n2. Steam the tempeh for about 10 minutes to remove any bitterness.\\n3. Marinate the tempeh in a mixture of soy sauce, sesame oil, and a pinch of black pepper for at least 15 minutes.\\n4. In a pan, heat some vegetable oil over medium heat and cook the marinated tempeh until browned and slightly crispy.\\n\\nFollow the rest of the recipe as instructed, replacing the beef with your prepared tofu or tempeh. Enjoy your vegetarian Bibimbap!\")"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_chain.invoke({\n",
    "    \"cuisine\": \"korean\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. MODEL IO\n",
    "\n",
    "### 4.1 FewShotPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "\n",
    "chat = ChatOpenAI(temperature=0.1, \n",
    "                  streaming=True, \n",
    "                  callbacks=[\n",
    "                      StreamingStdOutCallbackHandler(),\n",
    "                  ],\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Human: What do you know about France?\\nAI: \\n        Here is what I know:\\n        Capital: Paris\\n        Language: French\\n        Food: Wine and Cheese\\n        Currency: Euro\\n        \\n\\nHuman: What do you know about Italy?\\nAI: \\n        I know this:\\n        Capital: Rome\\n        Language: Italian\\n        Food: Pizza and Pasta\\n        Currency: Euro\\n        \\n\\nHuman: What do you know about Greece?\\nAI: \\n        I know this:\\n        Capital: Athens\\n        Language: Greek\\n        Food: Souvlaki and Feta Cheese\\n        Currency: Euro\\n        \\n\\nHuman: What do you know about Germany?'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples = [\n",
    "    {\n",
    "        \"question\": \"What do you know about France?\",\n",
    "        \"answer\": \"\"\"\n",
    "        Here is what I know:\n",
    "        Capital: Paris\n",
    "        Language: French\n",
    "        Food: Wine and Cheese\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What do you know about Italy?\",\n",
    "        \"answer\": \"\"\"\n",
    "        I know this:\n",
    "        Capital: Rome\n",
    "        Language: Italian\n",
    "        Food: Pizza and Pasta\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What do you know about Greece?\",\n",
    "        \"answer\": \"\"\"\n",
    "        I know this:\n",
    "        Capital: Athens\n",
    "        Language: Greek\n",
    "        Food: Souvlaki and Feta Cheese\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "]\n",
    "\n",
    "\n",
    "example_promt = PromptTemplate.from_template(\"Human: {question}\\nAI: {answer}\")\n",
    "\n",
    "prompt = FewShotPromptTemplate(\n",
    "    example_prompt=example_promt,\n",
    "    examples = examples,\n",
    "    suffix=\"Human: What do you know about {country}?\",\n",
    "    input_variables=[\"country\"],\n",
    ")\n",
    "\n",
    "prompt.format(country=\"Germany\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: \n",
      "        Here is what I know:\n",
      "        Capital: Berlin\n",
      "        Language: German\n",
      "        Food: Bratwurst and Sauerkraut\n",
      "        Currency: Euro"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessageChunk(content='AI: \\n        Here is what I know:\\n        Capital: Berlin\\n        Language: German\\n        Food: Bratwurst and Sauerkraut\\n        Currency: Euro')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt | chat\n",
    "\n",
    "chain.invoke({\n",
    "    \"country\": \"Germany\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 FewShotChatMessagePromptTemplate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        I know this:\n",
      "        Capital: Bangkok\n",
      "        Language: Thai\n",
      "        Food: Pad Thai and Tom Yum\n",
      "        Currency: Thai Baht\n",
      "        "
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessageChunk(content='\\n        I know this:\\n        Capital: Bangkok\\n        Language: Thai\\n        Food: Pad Thai and Tom Yum\\n        Currency: Thai Baht\\n        ')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts.few_shot import FewShotChatMessagePromptTemplate\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "examples = [\n",
    "    {\n",
    "        \"country\": \"France\",\n",
    "        \"answer\": \"\"\"\n",
    "        Here is what I know:\n",
    "        Capital: Paris\n",
    "        Language: French\n",
    "        Food: Wine and Cheese\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"country\": \"Italy\",\n",
    "        \"answer\": \"\"\"\n",
    "        I know this:\n",
    "        Capital: Rome\n",
    "        Language: Italian\n",
    "        Food: Pizza and Pasta\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"country\": \"Greece\",\n",
    "        \"answer\": \"\"\"\n",
    "        I know this:\n",
    "        Capital: Athens\n",
    "        Language: Greek\n",
    "        Food: Souvlaki and Feta Cheese\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "]\n",
    "\n",
    "\n",
    "example_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", \"What do you know about {country}?\"),\n",
    "        (\"ai\", \"{answer}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "example_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples,\n",
    ")\n",
    "\n",
    "final_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a geography expert, you give short answers.\"),\n",
    "        example_prompt,\n",
    "        (\"human\", \"What do you know about {country}?\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = final_prompt | chat\n",
    "\n",
    "chain.invoke({\"country\": \"Thailand\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 LengthBasedExampleSelector\n",
    "\n",
    "**4.3.1 LengthBasedExampleSelector**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: What do you know about France?\n",
      "AI: \n",
      "        Here is what I know:\n",
      "        Capital: Paris\n",
      "        Language: French\n",
      "        Food: Wine and Cheese\n",
      "        Currency: Euro\n",
      "        \n",
      "\n",
      "Human: What do you know about Italy?\n",
      "AI: \n",
      "        I know this:\n",
      "        Capital: Rome\n",
      "        Language: Italian\n",
      "        Food: Pizza and Pasta\n",
      "        Currency: Euro\n",
      "        \n",
      "\n",
      "Human: What do you know about Brazil?\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts.example_selector import LengthBasedExampleSelector\n",
    "\n",
    "examples = [\n",
    "    {\n",
    "        \"question\": \"What do you know about France?\",\n",
    "        \"answer\": \"\"\"\n",
    "        Here is what I know:\n",
    "        Capital: Paris\n",
    "        Language: French\n",
    "        Food: Wine and Cheese\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What do you know about Italy?\",\n",
    "        \"answer\": \"\"\"\n",
    "        I know this:\n",
    "        Capital: Rome\n",
    "        Language: Italian\n",
    "        Food: Pizza and Pasta\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What do you know about Greece?\",\n",
    "        \"answer\": \"\"\"\n",
    "        I know this:\n",
    "        Capital: Athens\n",
    "        Language: Greek\n",
    "        Food: Souvlaki and Feta Cheese\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "]\n",
    "\n",
    "example_prompt = PromptTemplate.from_template(\"Human: {question}\\nAI: {answer}\")\n",
    "\n",
    "example_selector = LengthBasedExampleSelector(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    max_length=200,\n",
    ")\n",
    "\n",
    "prompt = FewShotPromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    example_selector=example_selector,\n",
    "    suffix=\"Human: What do you know about {country}?\",\n",
    "    input_variables=[\"country\"],\n",
    ")\n",
    "\n",
    "print(prompt.format(country=\"Brazil\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.3.2 Random Example Selector**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict, List\n",
    "from langchain.prompts.example_selector.base import BaseExampleSelector\n",
    "\n",
    "class RandomExampleSelector(BaseExampleSelector):\n",
    "\n",
    "    def __init__(self, examples):\n",
    "        self.examples = examples\n",
    "    \n",
    "    def add_example(self, example):\n",
    "        self.examples.append(example)\n",
    "\n",
    "    def select_examples(self, input_variables):\n",
    "        from random import choice\n",
    "        return [choice(self.examples)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: What do you know about France?\n",
      "AI: \n",
      "        Here is what I know:\n",
      "        Capital: Paris\n",
      "        Language: French\n",
      "        Food: Wine and Cheese\n",
      "        Currency: Euro\n",
      "        \n",
      "\n",
      "Human: What do you know about Brazil?\n"
     ]
    }
   ],
   "source": [
    "example_prompt = PromptTemplate.from_template(\"Human: {question}\\nAI: {answer}\")\n",
    "example_selector = RandomExampleSelector(examples=examples)\n",
    "\n",
    "prompt = FewShotPromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    example_selector=example_selector,\n",
    "    suffix=\"Human: What do you know about {country}?\",\n",
    "    input_variables=[\"country\"],\n",
    ")\n",
    "\n",
    "print(prompt.format(country=\"Brazil\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Serialization and Composition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is the capital of Brazil'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import load_prompt\n",
    "\n",
    "prompt = load_prompt(\"./prompt.json\")\n",
    "prompt.format(country=\"Brazil\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is the capital of Brazil'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = load_prompt(\"./prompt.yaml\")\n",
    "prompt.format(country=\"Brazil\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    \n",
      "    You are a role playing assistant.\n",
      "    And you are impersonating a Priate\n",
      "\n",
      "                                     \n",
      "    \n",
      "    This is an example of how you talk:\n",
      "\n",
      "    Human: What is your location?\n",
      "    You: Arrrrg!! That is a secret!!!\n",
      "\n",
      "                              \n",
      "    \n",
      "    Start now!\n",
      "\n",
      "    Human: What is your favorite food?\n",
      "    You:\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts.pipeline import PipelinePromptTemplate\n",
    "\n",
    "intro = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    You are a role playing assistant.\n",
    "    And you are impersonating a {character}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "example = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    This is an example of how you talk:\n",
    "\n",
    "    Human: {example_question}\n",
    "    You: {example_answer}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "start = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    Start now!\n",
    "\n",
    "    Human: {question}\n",
    "    You:\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "final = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    {intro}\n",
    "                                     \n",
    "    {example}\n",
    "                              \n",
    "    {start}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "prompts = [(\"intro\", intro), (\"example\", example), (\"start\", start),]\n",
    "\n",
    "full_prompt = PipelinePromptTemplate(\n",
    "    final_prompt=final,\n",
    "    pipeline_prompts=prompts,\n",
    ")\n",
    "\n",
    "print(full_prompt.format(\n",
    "    character=\"Priate\",\n",
    "    example_question=\"What is your location?\",\n",
    "    example_answer=\"Arrrrg!! That is a secret!!!\",\n",
    "    question = \"What is your favorite food?\"\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arrrrg!! Me favorite food be a good ol' plate of rum-soaked sea biscuits! Aye, nothing beats the taste of salty biscuits washed down with a swig of me finest grog!"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessageChunk(content=\"Arrrrg!! Me favorite food be a good ol' plate of rum-soaked sea biscuits! Aye, nothing beats the taste of salty biscuits washed down with a swig of me finest grog!\")"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = full_prompt | chat\n",
    "\n",
    "chain.invoke({\n",
    "    \"character\":\"Priate\",\n",
    "    \"example_question\":\"What is your location?\",\n",
    "    \"example_answer\":\"Arrrrg!! That is a secret!!!\",\n",
    "    \"question\":\"What is your favorite food?\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Caching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To make an Italian pizza, you will need the following ingredients:\\n\\n- Pizza dough\\n- Tomato sauce\\n- Mozzarella cheese\\n- Fresh basil leaves\\n- Olive oil\\n- Salt and pepper\\n\\nInstructions:\\n\\n1. Preheat your oven to the highest temperature possible (usually around 500°F or 260°C).\\n\\n2. Roll out your pizza dough on a floured surface to your desired thickness.\\n\\n3. Place the rolled out dough on a pizza stone or baking sheet.\\n\\n4. Spread a thin layer of tomato sauce over the dough, leaving a small border around the edges.\\n\\n5. Sprinkle a generous amount of shredded mozzarella cheese over the sauce.\\n\\n6. Tear fresh basil leaves and scatter them over the cheese.\\n\\n7. Drizzle a little olive oil over the top and season with salt and pepper.\\n\\n8. Place the pizza in the preheated oven and bake for about 10-15 minutes, or until the crust is golden brown and the cheese is melted and bubbly.\\n\\n9. Remove the pizza from the oven and let it cool slightly before slicing and serving.\\n\\nEnjoy your delicious Italian pizza!'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.globals import set_llm_cache\n",
    "from langchain.cache import InMemoryCache\n",
    "\n",
    "set_llm_cache(InMemoryCache())\n",
    "\n",
    "chat = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "chat.predict(\"How do you make italia pizza?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To make an Italian pizza, you will need the following ingredients:\\n\\n- Pizza dough\\n- Tomato sauce\\n- Mozzarella cheese\\n- Fresh basil leaves\\n- Olive oil\\n- Salt and pepper\\n\\nInstructions:\\n\\n1. Preheat your oven to the highest temperature possible (usually around 500°F or 260°C).\\n\\n2. Roll out your pizza dough on a floured surface to your desired thickness.\\n\\n3. Place the rolled out dough on a pizza stone or baking sheet.\\n\\n4. Spread a thin layer of tomato sauce over the dough, leaving a small border around the edges.\\n\\n5. Sprinkle a generous amount of shredded mozzarella cheese over the sauce.\\n\\n6. Tear fresh basil leaves and scatter them over the cheese.\\n\\n7. Drizzle a little olive oil over the top and season with salt and pepper.\\n\\n8. Place the pizza in the preheated oven and bake for about 10-15 minutes, or until the crust is golden brown and the cheese is melted and bubbly.\\n\\n9. Remove the pizza from the oven and let it cool slightly before slicing and serving.\\n\\nEnjoy your delicious Italian pizza!'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.predict(\"How do you make italia pizza?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: How do you make italia pizza?\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:llm:ChatOpenAI] [2ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"To make an Italian pizza, you will need the following ingredients:\\n\\n- Pizza dough\\n- Tomato sauce\\n- Mozzarella cheese\\n- Fresh basil leaves\\n- Olive oil\\n- Salt and pepper\\n\\nInstructions:\\n\\n1. Preheat your oven to the highest temperature possible (usually around 500°F or 260°C).\\n\\n2. Roll out your pizza dough on a floured surface to your desired thickness.\\n\\n3. Place the rolled out dough on a pizza stone or baking sheet.\\n\\n4. Spread a thin layer of tomato sauce over the dough, leaving a small border around the edges.\\n\\n5. Sprinkle a generous amount of shredded mozzarella cheese over the sauce.\\n\\n6. Tear fresh basil leaves and scatter them over the cheese.\\n\\n7. Drizzle a little olive oil over the top and season with salt and pepper.\\n\\n8. Place the pizza in the preheated oven and bake for about 10-15 minutes, or until the crust is golden brown and the cheese is melted and bubbly.\\n\\n9. Remove the pizza from the oven and let it cool slightly before slicing and serving.\\n\\nEnjoy your delicious Italian pizza!\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\"\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"To make an Italian pizza, you will need the following ingredients:\\n\\n- Pizza dough\\n- Tomato sauce\\n- Mozzarella cheese\\n- Fresh basil leaves\\n- Olive oil\\n- Salt and pepper\\n\\nInstructions:\\n\\n1. Preheat your oven to the highest temperature possible (usually around 500°F or 260°C).\\n\\n2. Roll out your pizza dough on a floured surface to your desired thickness.\\n\\n3. Place the rolled out dough on a pizza stone or baking sheet.\\n\\n4. Spread a thin layer of tomato sauce over the dough, leaving a small border around the edges.\\n\\n5. Sprinkle a generous amount of shredded mozzarella cheese over the sauce.\\n\\n6. Tear fresh basil leaves and scatter them over the cheese.\\n\\n7. Drizzle a little olive oil over the top and season with salt and pepper.\\n\\n8. Place the pizza in the preheated oven and bake for about 10-15 minutes, or until the crust is golden brown and the cheese is melted and bubbly.\\n\\n9. Remove the pizza from the oven and let it cool slightly before slicing and serving.\\n\\nEnjoy your delicious Italian pizza!\",\n",
      "            \"additional_kwargs\": {}\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'To make an Italian pizza, you will need the following ingredients:\\n\\n- Pizza dough\\n- Tomato sauce\\n- Mozzarella cheese\\n- Fresh basil leaves\\n- Olive oil\\n- Salt and pepper\\n\\nInstructions:\\n\\n1. Preheat your oven to the highest temperature possible (usually around 500°F or 260°C).\\n\\n2. Roll out your pizza dough on a floured surface to your desired thickness.\\n\\n3. Place the rolled out dough on a pizza stone or baking sheet.\\n\\n4. Spread a thin layer of tomato sauce over the dough, leaving a small border around the edges.\\n\\n5. Sprinkle a generous amount of shredded mozzarella cheese over the sauce.\\n\\n6. Tear fresh basil leaves and scatter them over the cheese.\\n\\n7. Drizzle a little olive oil over the top and season with salt and pepper.\\n\\n8. Place the pizza in the preheated oven and bake for about 10-15 minutes, or until the crust is golden brown and the cheese is melted and bubbly.\\n\\n9. Remove the pizza from the oven and let it cool slightly before slicing and serving.\\n\\nEnjoy your delicious Italian pizza!'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.globals import set_debug\n",
    "\n",
    "set_debug(True)\n",
    "\n",
    "chat.predict(\"How do you make italia pizza?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: How do you make italia pizza?\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:llm:ChatOpenAI] [5.42s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"To make an Italian pizza, you will need the following ingredients:\\n\\n- Pizza dough (you can make your own or buy pre-made dough)\\n- Tomato sauce\\n- Mozzarella cheese\\n- Fresh basil leaves\\n- Olive oil\\n- Salt and pepper\\n- Toppings of your choice (such as pepperoni, mushrooms, bell peppers, etc.)\\n\\nHere is a basic recipe for making Italian pizza:\\n\\n1. Preheat your oven to the highest temperature possible (usually around 500°F or higher).\\n\\n2. Roll out the pizza dough on a floured surface to your desired thickness. Place the dough on a pizza stone or baking sheet.\\n\\n3. Spread a thin layer of tomato sauce over the dough, leaving a border around the edges for the crust.\\n\\n4. Sprinkle the mozzarella cheese evenly over the sauce.\\n\\n5. Add your desired toppings on top of the cheese.\\n\\n6. Drizzle a little olive oil over the top of the pizza and season with salt and pepper.\\n\\n7. Bake the pizza in the preheated oven for about 10-15 minutes, or until the crust is golden brown and the cheese is melted and bubbly.\\n\\n8. Remove the pizza from the oven and sprinkle fresh basil leaves on top before serving.\\n\\nEnjoy your homemade Italian pizza!\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\"\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"To make an Italian pizza, you will need the following ingredients:\\n\\n- Pizza dough (you can make your own or buy pre-made dough)\\n- Tomato sauce\\n- Mozzarella cheese\\n- Fresh basil leaves\\n- Olive oil\\n- Salt and pepper\\n- Toppings of your choice (such as pepperoni, mushrooms, bell peppers, etc.)\\n\\nHere is a basic recipe for making Italian pizza:\\n\\n1. Preheat your oven to the highest temperature possible (usually around 500°F or higher).\\n\\n2. Roll out the pizza dough on a floured surface to your desired thickness. Place the dough on a pizza stone or baking sheet.\\n\\n3. Spread a thin layer of tomato sauce over the dough, leaving a border around the edges for the crust.\\n\\n4. Sprinkle the mozzarella cheese evenly over the sauce.\\n\\n5. Add your desired toppings on top of the cheese.\\n\\n6. Drizzle a little olive oil over the top of the pizza and season with salt and pepper.\\n\\n7. Bake the pizza in the preheated oven for about 10-15 minutes, or until the crust is golden brown and the cheese is melted and bubbly.\\n\\n8. Remove the pizza from the oven and sprinkle fresh basil leaves on top before serving.\\n\\nEnjoy your homemade Italian pizza!\",\n",
      "            \"additional_kwargs\": {}\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"prompt_tokens\": 14,\n",
      "      \"completion_tokens\": 257,\n",
      "      \"total_tokens\": 271\n",
      "    },\n",
      "    \"model_name\": \"gpt-3.5-turbo\",\n",
      "    \"system_fingerprint\": null\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'To make an Italian pizza, you will need the following ingredients:\\n\\n- Pizza dough (you can make your own or buy pre-made dough)\\n- Tomato sauce\\n- Mozzarella cheese\\n- Fresh basil leaves\\n- Olive oil\\n- Salt and pepper\\n- Toppings of your choice (such as pepperoni, mushrooms, bell peppers, etc.)\\n\\nHere is a basic recipe for making Italian pizza:\\n\\n1. Preheat your oven to the highest temperature possible (usually around 500°F or higher).\\n\\n2. Roll out the pizza dough on a floured surface to your desired thickness. Place the dough on a pizza stone or baking sheet.\\n\\n3. Spread a thin layer of tomato sauce over the dough, leaving a border around the edges for the crust.\\n\\n4. Sprinkle the mozzarella cheese evenly over the sauce.\\n\\n5. Add your desired toppings on top of the cheese.\\n\\n6. Drizzle a little olive oil over the top of the pizza and season with salt and pepper.\\n\\n7. Bake the pizza in the preheated oven for about 10-15 minutes, or until the crust is golden brown and the cheese is melted and bubbly.\\n\\n8. Remove the pizza from the oven and sprinkle fresh basil leaves on top before serving.\\n\\nEnjoy your homemade Italian pizza!'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.cache import SQLiteCache\n",
    "\n",
    "set_llm_cache(SQLiteCache('cache.db'))\n",
    "\n",
    "chat.predict(\"How do you make italia pizza?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: How do you make italia pizza!?\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:llm:ChatOpenAI] [1ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"To make an Italian pizza, you will need the following ingredients:\\n\\n- Pizza dough (you can make your own or buy pre-made dough)\\n- Tomato sauce\\n- Mozzarella cheese\\n- Fresh basil leaves\\n- Olive oil\\n- Salt and pepper\\n- Toppings of your choice (such as pepperoni, mushrooms, bell peppers, etc.)\\n\\nHere is a basic recipe for making an Italian pizza:\\n\\n1. Preheat your oven to the highest temperature possible (usually around 500°F or 260°C).\\n\\n2. Roll out your pizza dough on a floured surface to your desired thickness.\\n\\n3. Place the dough on a pizza stone or baking sheet lined with parchment paper.\\n\\n4. Spread a thin layer of tomato sauce over the dough, leaving a small border around the edges.\\n\\n5. Sprinkle a generous amount of shredded mozzarella cheese over the sauce.\\n\\n6. Add your desired toppings on top of the cheese.\\n\\n7. Drizzle a little olive oil over the top of the pizza and season with salt and pepper.\\n\\n8. Bake the pizza in the preheated oven for about 10-15 minutes, or until the crust is golden brown and the cheese is bubbly and melted.\\n\\n9. Remove the pizza from the oven and garnish with fresh basil leaves before serving.\\n\\nEnjoy your delicious Italian pizza!\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\"\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"To make an Italian pizza, you will need the following ingredients:\\n\\n- Pizza dough (you can make your own or buy pre-made dough)\\n- Tomato sauce\\n- Mozzarella cheese\\n- Fresh basil leaves\\n- Olive oil\\n- Salt and pepper\\n- Toppings of your choice (such as pepperoni, mushrooms, bell peppers, etc.)\\n\\nHere is a basic recipe for making an Italian pizza:\\n\\n1. Preheat your oven to the highest temperature possible (usually around 500°F or 260°C).\\n\\n2. Roll out your pizza dough on a floured surface to your desired thickness.\\n\\n3. Place the dough on a pizza stone or baking sheet lined with parchment paper.\\n\\n4. Spread a thin layer of tomato sauce over the dough, leaving a small border around the edges.\\n\\n5. Sprinkle a generous amount of shredded mozzarella cheese over the sauce.\\n\\n6. Add your desired toppings on top of the cheese.\\n\\n7. Drizzle a little olive oil over the top of the pizza and season with salt and pepper.\\n\\n8. Bake the pizza in the preheated oven for about 10-15 minutes, or until the crust is golden brown and the cheese is bubbly and melted.\\n\\n9. Remove the pizza from the oven and garnish with fresh basil leaves before serving.\\n\\nEnjoy your delicious Italian pizza!\",\n",
      "            \"additional_kwargs\": {}\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'To make an Italian pizza, you will need the following ingredients:\\n\\n- Pizza dough (you can make your own or buy pre-made dough)\\n- Tomato sauce\\n- Mozzarella cheese\\n- Fresh basil leaves\\n- Olive oil\\n- Salt and pepper\\n- Toppings of your choice (such as pepperoni, mushrooms, bell peppers, etc.)\\n\\nHere is a basic recipe for making an Italian pizza:\\n\\n1. Preheat your oven to the highest temperature possible (usually around 500°F or 260°C).\\n\\n2. Roll out your pizza dough on a floured surface to your desired thickness.\\n\\n3. Place the dough on a pizza stone or baking sheet lined with parchment paper.\\n\\n4. Spread a thin layer of tomato sauce over the dough, leaving a small border around the edges.\\n\\n5. Sprinkle a generous amount of shredded mozzarella cheese over the sauce.\\n\\n6. Add your desired toppings on top of the cheese.\\n\\n7. Drizzle a little olive oil over the top of the pizza and season with salt and pepper.\\n\\n8. Bake the pizza in the preheated oven for about 10-15 minutes, or until the crust is golden brown and the cheese is bubbly and melted.\\n\\n9. Remove the pizza from the oven and garnish with fresh basil leaves before serving.\\n\\nEnjoy your delicious Italian pizza!'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.predict(\"How do you make italia pizza!?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6 Serialization\n",
    "\n",
    "**4.6.1 get_openai_callback**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: What is the recipe for soju\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:llm:ChatOpenAI] [4.03s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"Ingredients:\\n- 1 cup of rice\\n- 1 cup of water\\n- 1 tablespoon of nuruk (fermentation starter)\\n- 1 tablespoon of yeast\\n\\nInstructions:\\n1. Rinse the rice thoroughly and soak it in water for at least 1 hour.\\n2. Drain the rice and steam it until it is fully cooked.\\n3. Let the rice cool down to room temperature.\\n4. In a large bowl, mix the nuruk and yeast with the cooked rice.\\n5. Cover the bowl with a clean cloth and let it ferment for 3-4 days in a warm place.\\n6. After fermentation, strain the mixture through a cheesecloth to separate the liquid from the solids.\\n7. Transfer the liquid to a clean container and let it sit for another 2-3 days to allow the flavors to develop.\\n8. Your homemade soju is now ready to be enjoyed! Serve chilled and enjoy responsibly.\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\"\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"Ingredients:\\n- 1 cup of rice\\n- 1 cup of water\\n- 1 tablespoon of nuruk (fermentation starter)\\n- 1 tablespoon of yeast\\n\\nInstructions:\\n1. Rinse the rice thoroughly and soak it in water for at least 1 hour.\\n2. Drain the rice and steam it until it is fully cooked.\\n3. Let the rice cool down to room temperature.\\n4. In a large bowl, mix the nuruk and yeast with the cooked rice.\\n5. Cover the bowl with a clean cloth and let it ferment for 3-4 days in a warm place.\\n6. After fermentation, strain the mixture through a cheesecloth to separate the liquid from the solids.\\n7. Transfer the liquid to a clean container and let it sit for another 2-3 days to allow the flavors to develop.\\n8. Your homemade soju is now ready to be enjoyed! Serve chilled and enjoy responsibly.\",\n",
      "            \"additional_kwargs\": {}\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"prompt_tokens\": 14,\n",
      "      \"completion_tokens\": 190,\n",
      "      \"total_tokens\": 204\n",
      "    },\n",
      "    \"model_name\": \"gpt-3.5-turbo\",\n",
      "    \"system_fingerprint\": null\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "Tokens Used: 204\n",
      "\tPrompt Tokens: 14\n",
      "\tCompletion Tokens: 190\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.00040100000000000004\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.callbacks import get_openai_callback\n",
    "\n",
    "with get_openai_callback() as usage:\n",
    "    chat.predict(\"What is the recipe for soju\")\n",
    "    print(usage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.6.2 Serialization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.llms.openai import OpenAI\n",
    "\n",
    "chat = OpenAI(\n",
    "    temperature=0.1,\n",
    "    max_tokens=450,\n",
    "    model='gpt-3.5-turbo-16k',\n",
    ")\n",
    "\n",
    "chat.save(\"model.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mOpenAIChat\u001b[0m\n",
      "Params: {'model_name': 'gpt-3.5-turbo-16k', 'temperature': 0.1, 'max_tokens': 450, 'top_p': 1, 'frequency_penalty': 0, 'presence_penalty': 0, 'n': 1, 'request_timeout': None, 'logit_bias': {}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sigi/hanwha_project/langchain_study/kang/env/lib/python3.11/site-packages/langchain/llms/openai.py:216: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n",
      "/Users/sigi/hanwha_project/langchain_study/kang/env/lib/python3.11/site-packages/langchain/llms/openai.py:811: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms.loading import load_llm\n",
    "chat = load_llm(\"model.json\")\n",
    "print(chat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.0 ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content='Hi!'), AIMessage(content='How are you?')]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory(return_messages=True)\n",
    "\n",
    "memory.save_context({\"input\": \"Hi!\"}, {\"output\":\"How are you?\"})\n",
    "\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content='Hi!'),\n",
       "  AIMessage(content='How are you?'),\n",
       "  HumanMessage(content='Hi!'),\n",
       "  AIMessage(content='How are you?')]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.save_context({\"input\": \"Hi!\"}, {\"output\":\"How are you?\"})\n",
    "\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 ConversationBufferWindowMemory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content='1'),\n",
       "  AIMessage(content='1'),\n",
       "  HumanMessage(content='2'),\n",
       "  AIMessage(content='2'),\n",
       "  HumanMessage(content='3'),\n",
       "  AIMessage(content='3'),\n",
       "  HumanMessage(content='4'),\n",
       "  AIMessage(content='4')]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "\n",
    "memory = ConversationBufferWindowMemory(\n",
    "    return_messages=True,\n",
    "    k=4\n",
    ")\n",
    "\n",
    "def add_message(input, output):\n",
    "    memory.save_context({\"input\": input}, {\"output\": output})\n",
    "\n",
    "add_message(1,1)\n",
    "add_message(2,2)\n",
    "add_message(3,3)\n",
    "add_message(4,4)\n",
    "\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content='2'),\n",
       "  AIMessage(content='2'),\n",
       "  HumanMessage(content='3'),\n",
       "  AIMessage(content='3'),\n",
       "  HumanMessage(content='4'),\n",
       "  AIMessage(content='4'),\n",
       "  HumanMessage(content='5'),\n",
       "  AIMessage(content='5')]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_message(5,5)\n",
    "\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 ConversationSummaryMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryMemory\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "memory = ConversationSummaryMemory(llm=llm)\n",
    "\n",
    "def add_message(input, output):\n",
    "    memory.save_context({\"input\": input}, {\"output\": output})\n",
    "\n",
    "\n",
    "def get_history():\n",
    "    return memory.load_memory_variables({})\n",
    "\n",
    "\n",
    "add_message(\"Hi I'm Nicolas, I live in South Korea\", \"Wow that is so cool!\")\n",
    "add_message(\"South Kddorea is so pretty\", \"I wish I could go!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Nicolas from South Korea introduces himself to the AI, who responds enthusiastically. The human mentions how pretty South Korea is, prompting the AI to express a desire to visit.'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_history()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 ConversationSummaryBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content=\"Hi I'm Nicolas, I live in South Korea\"),\n",
       "  AIMessage(content='Wow that is so cool!')]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(\n",
    "    llm=llm,\n",
    "    max_token_limit=50,\n",
    "    return_messages=True,\n",
    ")\n",
    "\n",
    "\n",
    "def add_message(input, output):\n",
    "    memory.save_context({\"input\": input}, {\"output\": output})\n",
    "\n",
    "\n",
    "def get_history():\n",
    "    return memory.load_memory_variables({})\n",
    "\n",
    "\n",
    "add_message(\"Hi I'm Nicolas, I live in South Korea\", \"Wow that is so cool!\")\n",
    "get_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content=\"Hi I'm Nicolas, I live in South Korea\"),\n",
       "  AIMessage(content='Wow that is so cool!'),\n",
       "  HumanMessage(content='South Korea is so pretty'),\n",
       "  AIMessage(content='I wish I could go!!!')]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_message(\"South Korea is so pretty\", \"I wish I could go!!!\")\n",
    "get_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [SystemMessage(content=\"The human introduces himself as Nicolas from South Korea. The AI responds by expressing admiration for Nicolas's location.\"),\n",
       "  HumanMessage(content='South Korea is so pretty'),\n",
       "  AIMessage(content='I wish I could go!!!'),\n",
       "  HumanMessage(content='How far is Korea from Argentina?'),\n",
       "  AIMessage(content=\"I don't know! Super far!\")]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_message(\"How far is Korea from Argentina?\", \"I don't know! Super far!\")\n",
    "get_history()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 ConversationKGMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [SystemMessage(content='On Nicolas: Nicolas lives in South Korea.')]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ConversationKGMemory\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "memory = ConversationKGMemory(\n",
    "    llm=llm,\n",
    "    return_messages=True,\n",
    ")\n",
    "\n",
    "def add_message(input, output):\n",
    "    memory.save_context({\"input\": input}, {\"output\": output})\n",
    "\n",
    "add_message(\"Hi I'm Nicolas, I live in South Korea\", \"Wow that is so cool!\")\n",
    "memory.load_memory_variables({\"input\": \"who is Nicolas\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [SystemMessage(content='On Nicolas: Nicolas lives in South Korea. Nicolas likes kimchi.')]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_message(\"Nicolas likes kimchi\", \"Wow that is so cool!\")\n",
    "memory.load_memory_variables({\"inputs\": \"what does nicolas like\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5 Memory on LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "    You are a chatbot that helps people with their daily life.\n",
      "\n",
      "    \n",
      "    Human: My name is Nico\n",
      "    AI:\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Nice to meet you, Nico! How can I assist you today?'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(\n",
    "    llm=llm,\n",
    "    max_token_limit=50,\n",
    "    memory_key=\"chat_history\",\n",
    ")\n",
    "\n",
    "template = \"\"\"\n",
    "    You are a chatbot that helps people with their daily life.\n",
    "\n",
    "    {chat_history}\n",
    "    Human: {question}\n",
    "    AI:\n",
    "\"\"\"\n",
    "\n",
    "chain = LLMChain(\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    "    prompt=PromptTemplate.from_template(template),\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "chain.predict(question=\"My name is Nico\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "    You are a chatbot that helps people with their daily life.\n",
      "\n",
      "    Human: My name is Nico\n",
      "AI: Nice to meet you, Nico! How can I assist you today?\n",
      "    Human: I`m living in seoul.\n",
      "    AI:\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"That's great to hear! How are you finding living in Seoul? Is there anything specific you need help with in your daily life there?\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.predict(question=\"I`m living in seoul.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "    You are a chatbot that helps people with their daily life.\n",
      "\n",
      "    System: The human introduces themselves as Nico. The AI responds by saying it's nice to meet Nico and asks how it can assist them today.\n",
      "Human: I`m living in seoul.\n",
      "AI: That's great to hear! How are you finding living in Seoul? Is there anything specific you need help with in your daily life there?\n",
      "    Human: what is my name?\n",
      "    AI:\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Your name is Nico.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.predict(question=\"what is my name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'chat_history': 'System: Nico introduces themselves and mentions they are living in Seoul. The AI responds positively and asks how they are finding living in Seoul, offering assistance with anything specific in their daily life there.\\nHuman: what is my name?\\nAI: Your name is Nico.'}\n"
     ]
    }
   ],
   "source": [
    "print(memory.load_memory_variables({}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
