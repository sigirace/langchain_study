{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.0 LLMs and Chat Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms.openai import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(model_name=\"gpt-3.5-turbo-1106\")\n",
    "chat = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = llm.predict(\"How many planets are there?\")\n",
    "b = llm.predict(\"How many planets are there?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('As of current scientific understanding, there are 8 planets in our solar system: Mercury, Venus, Earth, Mars, Jupiter, Saturn, Uranus, and Neptune. Please note that the status of Pluto as a planet is a matter of ongoing debate and is not universally accepted.',\n",
       " 'There are eight recognized planets in our solar system: Mercury, Venus, Earth, Mars, Jupiter, Saturn, Uranus, and Neptune.')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a, b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Predict Messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import HumanMessage, AIMessage, SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='멕시코와 태국 사이의 거리는 약 14,000km 정도 되요. 제 이름은 딩고에요!')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    SystemMessage(content='you are a geograph expert. and you only reply in Korea.'),\n",
    "    AIMessage(content='와우! 제 이름은 딩고에요!'),\n",
    "    HumanMessage(content=\"맥시코와 태국 사이의 거리는 얼마인가. 그리고 너의 이름은 무엇이니?\"),\n",
    "]\n",
    "\n",
    "chat.predict_messages(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Prompt Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.2.1 PromptTemplate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'what is the distance between Mexico and Thailand'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template = PromptTemplate.from_template(\"what is the distance between {country_a} and {country_b}\",)\n",
    "\n",
    "template.format(country_a=\"Mexico\", country_b=\"Thailand\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_variables': ['country_a', 'country_b'],\n",
       " 'input_types': {},\n",
       " 'output_parser': None,\n",
       " 'partial_variables': {},\n",
       " 'template': 'what is the distance between {country_a} and {country_b}',\n",
       " 'template_format': 'f-string',\n",
       " 'validate_template': False}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The distance between Mexico and Thailand is approximately 9,500 miles (15,300 kilometers) when measured in a straight line.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = template.format(country_a=\"Mexico\", country_b=\"Thailand\")\n",
    "\n",
    "chat = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "chat.predict(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.2.2 ChatPromptTemplate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_variables': ['country_a', 'country_b', 'language', 'name'],\n",
       " 'input_types': {},\n",
       " 'output_parser': None,\n",
       " 'partial_variables': {},\n",
       " 'messages': [SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['language'], template='you are a geograph expert. and you only reply in {language}.')),\n",
       "  AIMessagePromptTemplate(prompt=PromptTemplate(input_variables=['name'], template='와우! 제 이름은 {name}에요!')),\n",
       "  HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['country_a', 'country_b'], template='{country_a}와 {country_b} 사이의 거리는 얼마인가. 그리고 너의 이름은 무엇이니?'))],\n",
       " 'validate_template': False}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"you are a geograph expert. and you only reply in {language}.\",),\n",
    "    (\"ai\", \"와우! 제 이름은 {name}에요!\",),\n",
    "    (\"human\", \"{country_a}와 {country_b} 사이의 거리는 얼마인가. 그리고 너의 이름은 무엇이니?\",),],\n",
    ")\n",
    "\n",
    "vars(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='you are a geograph expert. and you only reply in Korea.'), AIMessage(content='와우! 제 이름은 딩고에요!'), HumanMessage(content='Mexico와 Thailand 사이의 거리는 얼마인가. 그리고 너의 이름은 무엇이니?')]\n"
     ]
    }
   ],
   "source": [
    "prompt = messages.format_messages(\n",
    "    language=\"Korea\",\n",
    "    name=\"딩고\",\n",
    "    country_a=\"Mexico\",\n",
    "    country_b=\"Thailand\",\n",
    ")\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='멕시코와 태국 사이의 거리는 약 15,000km 정도 되요. 제 이름은 딩고에요!')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.predict_messages(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 OutputParser and LCEL\n",
    "\n",
    "**3.3.1 OutputParser**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello', 'how', 'are', 'you?']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.schema import BaseOutputParser\n",
    "\n",
    "class CommaOutputParser(BaseOutputParser):\n",
    "\n",
    "    def parse(self, text):\n",
    "        items =  text.strip().split(\",\")\n",
    "        return list(map(str.strip, items))\n",
    "\n",
    "p = CommaOutputParser()\n",
    "\n",
    "p.parse(\"Hello, how, are, you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='You are a list generating machine. Everything you ar asked will be answered with a comma seperated list of max 10 in lowercase. Do Not reply with anything else.'), HumanMessage(content='What are the colors?')]\n"
     ]
    }
   ],
   "source": [
    "template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a list generating machine. Everything you ar asked will be answered with a comma seperated list of max {max_items} in lowercase. Do Not reply with anything else.\"),\n",
    "    (\"human\", \"{question}\"),\n",
    "])\n",
    "\n",
    "prompt = template.format_messages(\n",
    "    max_items = 10,\n",
    "    question=\"What are the colors?\"\n",
    ")\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='red, blue, green, yellow, orange, purple, pink, black, white, brown')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.predict_messages(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['red',\n",
       " 'blue',\n",
       " 'green',\n",
       " 'yellow',\n",
       " 'orange',\n",
       " 'purple',\n",
       " 'pink',\n",
       " 'black',\n",
       " 'white',\n",
       " 'brown']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = chat.predict_messages(prompt)\n",
    "p = CommaOutputParser()\n",
    "parse_result = p.parse(result.content)\n",
    "parse_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(parse_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.3.2 LCEL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = template | chat | p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars(chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pikachu', 'charmander', 'bulbasaur', 'squirtle', 'jigglypuff']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\n",
    "    \"max_items\": 5,\n",
    "    \"question\": \"What are the pokemons?\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Chaining Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "\n",
    "chat = ChatOpenAI(temperature=0.1, streaming=True, callbacks=[StreamingStdOutCallbackHandler(),],)\n",
    "\n",
    "chef_promt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a world-class international chef. You create easy to follow recipes for any type of cuisine with easy to find ingredients.\"),\n",
    "    (\"human\", \"I wnat to cook {cuisine} food.\"),\n",
    "])\n",
    "\n",
    "chef_chain = chef_promt | chat\n",
    "\n",
    "vars(chef_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "veg_chef_promt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a vegetarian chef specialized on making traditional recipies vegetarian. You find alternative ingredients and explain their preparation. You don't radically modify the recipe. If there is no alternative for a food just say you don't know how to replace it.\"\n",
    "),\n",
    "    (\"human\", \"{recipe}\"),\n",
    "])\n",
    "\n",
    "veg_chain = veg_chef_promt | chat\n",
    "\n",
    "vars(veg_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_chain = {\"recipe\" : chef_chain} | veg_chain\n",
    "\n",
    "vars(final_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Great choice! How about making a classic Korean dish called Bibimbap? It's a delicious and colorful mixed rice bowl that's packed with flavor. Here's a simple recipe for you to try:\n",
      "\n",
      "Ingredients:\n",
      "- 1 cup of cooked white rice\n",
      "- 1 carrot, julienned\n",
      "- 1 zucchini, julienned\n",
      "- 1 cup of spinach\n",
      "- 1 cup of bean sprouts\n",
      "- 4 shiitake mushrooms, sliced\n",
      "- 1/2 pound of beef (you can use ribeye or sirloin), thinly sliced\n",
      "- 4 eggs\n",
      "- Sesame oil\n",
      "- Soy sauce\n",
      "- Gochujang (Korean chili paste)\n",
      "- Sesame seeds\n",
      "- Salt and pepper\n",
      "- Vegetable oil\n",
      "\n",
      "Instructions:\n",
      "1. Marinate the beef: In a bowl, mix the beef slices with 2 tablespoons of soy sauce, 1 tablespoon of sesame oil, and a pinch of black pepper. Let it marinate for at least 15 minutes.\n",
      "2. Cook the rice according to package instructions and set aside.\n",
      "3. In a pan, heat some vegetable oil over medium heat. Stir-fry the carrots, zucchini, and mushrooms separately until they are cooked but still slightly crunchy. Season each with a pinch of salt.\n",
      "4. Blanch the spinach and bean sprouts in boiling water for about 1 minute. Drain and squeeze out excess water. Season each with a pinch of salt and a drizzle of sesame oil.\n",
      "5. In the same pan, cook the marinated beef until browned and cooked through.\n",
      "6. In a separate pan, fry the eggs sunny-side up or however you prefer.\n",
      "7. To assemble the Bibimbap, divide the rice into bowls. Arrange the cooked vegetables and beef on top of the rice. Place a fried egg on top of each bowl.\n",
      "8. Serve with a side of gochujang and sprinkle with sesame seeds.\n",
      "9. Mix everything together before eating to enjoy all the flavors combined.\n",
      "\n",
      "Enjoy your homemade Bibimbap! Feel free to customize it with your favorite vegetables or protein. Let me know if you have any questions or need more Korean recipe ideas.For a vegetarian version of Bibimbap, you can easily substitute the beef with tofu or tempeh. Here's how you can prepare the tofu or tempeh as a replacement for the beef:\n",
      "\n",
      "**Tofu:**\n",
      "1. Use firm or extra-firm tofu for this recipe. Press the tofu to remove excess water by wrapping it in a clean kitchen towel and placing a heavy object on top for about 15-20 minutes.\n",
      "2. Cut the tofu into thin slices or cubes, depending on your preference.\n",
      "3. Marinate the tofu in a mixture of soy sauce, sesame oil, and a pinch of black pepper for at least 15 minutes.\n",
      "4. In a pan, heat some vegetable oil over medium heat and cook the marinated tofu until browned and slightly crispy.\n",
      "\n",
      "**Tempeh:**\n",
      "1. Cut the tempeh into thin slices or cubes.\n",
      "2. Steam the tempeh for about 10 minutes to remove any bitterness.\n",
      "3. Marinate the tempeh in a mixture of soy sauce, sesame oil, and a pinch of black pepper for at least 15 minutes.\n",
      "4. In a pan, heat some vegetable oil over medium heat and cook the marinated tempeh until browned and slightly crispy.\n",
      "\n",
      "Follow the rest of the recipe as instructed, replacing the beef with your prepared tofu or tempeh. Enjoy your vegetarian Bibimbap!"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessageChunk(content=\"For a vegetarian version of Bibimbap, you can easily substitute the beef with tofu or tempeh. Here's how you can prepare the tofu or tempeh as a replacement for the beef:\\n\\n**Tofu:**\\n1. Use firm or extra-firm tofu for this recipe. Press the tofu to remove excess water by wrapping it in a clean kitchen towel and placing a heavy object on top for about 15-20 minutes.\\n2. Cut the tofu into thin slices or cubes, depending on your preference.\\n3. Marinate the tofu in a mixture of soy sauce, sesame oil, and a pinch of black pepper for at least 15 minutes.\\n4. In a pan, heat some vegetable oil over medium heat and cook the marinated tofu until browned and slightly crispy.\\n\\n**Tempeh:**\\n1. Cut the tempeh into thin slices or cubes.\\n2. Steam the tempeh for about 10 minutes to remove any bitterness.\\n3. Marinate the tempeh in a mixture of soy sauce, sesame oil, and a pinch of black pepper for at least 15 minutes.\\n4. In a pan, heat some vegetable oil over medium heat and cook the marinated tempeh until browned and slightly crispy.\\n\\nFollow the rest of the recipe as instructed, replacing the beef with your prepared tofu or tempeh. Enjoy your vegetarian Bibimbap!\")"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_chain.invoke({\n",
    "    \"cuisine\": \"korean\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. MODEL IO\n",
    "\n",
    "### 4.1 FewShotPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "\n",
    "chat = ChatOpenAI(temperature=0.1, \n",
    "                  streaming=True, \n",
    "                  callbacks=[\n",
    "                      StreamingStdOutCallbackHandler(),\n",
    "                  ],\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Human: What do you know about France?\\nAI: \\n        Here is what I know:\\n        Capital: Paris\\n        Language: French\\n        Food: Wine and Cheese\\n        Currency: Euro\\n        \\n\\nHuman: What do you know about Italy?\\nAI: \\n        I know this:\\n        Capital: Rome\\n        Language: Italian\\n        Food: Pizza and Pasta\\n        Currency: Euro\\n        \\n\\nHuman: What do you know about Greece?\\nAI: \\n        I know this:\\n        Capital: Athens\\n        Language: Greek\\n        Food: Souvlaki and Feta Cheese\\n        Currency: Euro\\n        \\n\\nHuman: What do you know about Germany?'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples = [\n",
    "    {\n",
    "        \"question\": \"What do you know about France?\",\n",
    "        \"answer\": \"\"\"\n",
    "        Here is what I know:\n",
    "        Capital: Paris\n",
    "        Language: French\n",
    "        Food: Wine and Cheese\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What do you know about Italy?\",\n",
    "        \"answer\": \"\"\"\n",
    "        I know this:\n",
    "        Capital: Rome\n",
    "        Language: Italian\n",
    "        Food: Pizza and Pasta\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What do you know about Greece?\",\n",
    "        \"answer\": \"\"\"\n",
    "        I know this:\n",
    "        Capital: Athens\n",
    "        Language: Greek\n",
    "        Food: Souvlaki and Feta Cheese\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "]\n",
    "\n",
    "\n",
    "example_promt = PromptTemplate.from_template(\"Human: {question}\\nAI: {answer}\")\n",
    "\n",
    "prompt = FewShotPromptTemplate(\n",
    "    example_prompt=example_promt,\n",
    "    examples = examples,\n",
    "    suffix=\"Human: What do you know about {country}?\",\n",
    "    input_variables=[\"country\"],\n",
    ")\n",
    "\n",
    "prompt.format(country=\"Germany\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: \n",
      "        Here is what I know:\n",
      "        Capital: Berlin\n",
      "        Language: German\n",
      "        Food: Bratwurst and Sauerkraut\n",
      "        Currency: Euro"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessageChunk(content='AI: \\n        Here is what I know:\\n        Capital: Berlin\\n        Language: German\\n        Food: Bratwurst and Sauerkraut\\n        Currency: Euro')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt | chat\n",
    "\n",
    "chain.invoke({\n",
    "    \"country\": \"Germany\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 FewShotChatMessagePromptTemplate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        I know this:\n",
      "        Capital: Bangkok\n",
      "        Language: Thai\n",
      "        Food: Pad Thai and Tom Yum\n",
      "        Currency: Thai Baht\n",
      "        "
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessageChunk(content='\\n        I know this:\\n        Capital: Bangkok\\n        Language: Thai\\n        Food: Pad Thai and Tom Yum\\n        Currency: Thai Baht\\n        ')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts.few_shot import FewShotChatMessagePromptTemplate\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "examples = [\n",
    "    {\n",
    "        \"country\": \"France\",\n",
    "        \"answer\": \"\"\"\n",
    "        Here is what I know:\n",
    "        Capital: Paris\n",
    "        Language: French\n",
    "        Food: Wine and Cheese\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"country\": \"Italy\",\n",
    "        \"answer\": \"\"\"\n",
    "        I know this:\n",
    "        Capital: Rome\n",
    "        Language: Italian\n",
    "        Food: Pizza and Pasta\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"country\": \"Greece\",\n",
    "        \"answer\": \"\"\"\n",
    "        I know this:\n",
    "        Capital: Athens\n",
    "        Language: Greek\n",
    "        Food: Souvlaki and Feta Cheese\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "]\n",
    "\n",
    "\n",
    "example_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", \"What do you know about {country}?\"),\n",
    "        (\"ai\", \"{answer}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "example_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples,\n",
    ")\n",
    "\n",
    "final_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a geography expert, you give short answers.\"),\n",
    "        example_prompt,\n",
    "        (\"human\", \"What do you know about {country}?\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = final_prompt | chat\n",
    "\n",
    "chain.invoke({\"country\": \"Thailand\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 LengthBasedExampleSelector\n",
    "\n",
    "**4.3.1 LengthBasedExampleSelector**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: What do you know about France?\n",
      "AI: \n",
      "        Here is what I know:\n",
      "        Capital: Paris\n",
      "        Language: French\n",
      "        Food: Wine and Cheese\n",
      "        Currency: Euro\n",
      "        \n",
      "\n",
      "Human: What do you know about Italy?\n",
      "AI: \n",
      "        I know this:\n",
      "        Capital: Rome\n",
      "        Language: Italian\n",
      "        Food: Pizza and Pasta\n",
      "        Currency: Euro\n",
      "        \n",
      "\n",
      "Human: What do you know about Brazil?\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts.example_selector import LengthBasedExampleSelector\n",
    "\n",
    "examples = [\n",
    "    {\n",
    "        \"question\": \"What do you know about France?\",\n",
    "        \"answer\": \"\"\"\n",
    "        Here is what I know:\n",
    "        Capital: Paris\n",
    "        Language: French\n",
    "        Food: Wine and Cheese\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What do you know about Italy?\",\n",
    "        \"answer\": \"\"\"\n",
    "        I know this:\n",
    "        Capital: Rome\n",
    "        Language: Italian\n",
    "        Food: Pizza and Pasta\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What do you know about Greece?\",\n",
    "        \"answer\": \"\"\"\n",
    "        I know this:\n",
    "        Capital: Athens\n",
    "        Language: Greek\n",
    "        Food: Souvlaki and Feta Cheese\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "]\n",
    "\n",
    "example_prompt = PromptTemplate.from_template(\"Human: {question}\\nAI: {answer}\")\n",
    "\n",
    "example_selector = LengthBasedExampleSelector(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    max_length=200,\n",
    ")\n",
    "\n",
    "prompt = FewShotPromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    example_selector=example_selector,\n",
    "    suffix=\"Human: What do you know about {country}?\",\n",
    "    input_variables=[\"country\"],\n",
    ")\n",
    "\n",
    "print(prompt.format(country=\"Brazil\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.3.2 Random Example Selector**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict, List\n",
    "from langchain.prompts.example_selector.base import BaseExampleSelector\n",
    "\n",
    "class RandomExampleSelector(BaseExampleSelector):\n",
    "\n",
    "    def __init__(self, examples):\n",
    "        self.examples = examples\n",
    "    \n",
    "    def add_example(self, example):\n",
    "        self.examples.append(example)\n",
    "\n",
    "    def select_examples(self, input_variables):\n",
    "        from random import choice\n",
    "        return [choice(self.examples)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: What do you know about France?\n",
      "AI: \n",
      "        Here is what I know:\n",
      "        Capital: Paris\n",
      "        Language: French\n",
      "        Food: Wine and Cheese\n",
      "        Currency: Euro\n",
      "        \n",
      "\n",
      "Human: What do you know about Brazil?\n"
     ]
    }
   ],
   "source": [
    "example_prompt = PromptTemplate.from_template(\"Human: {question}\\nAI: {answer}\")\n",
    "example_selector = RandomExampleSelector(examples=examples)\n",
    "\n",
    "prompt = FewShotPromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    example_selector=example_selector,\n",
    "    suffix=\"Human: What do you know about {country}?\",\n",
    "    input_variables=[\"country\"],\n",
    ")\n",
    "\n",
    "print(prompt.format(country=\"Brazil\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Serialization and Composition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is the capital of Brazil'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import load_prompt\n",
    "\n",
    "prompt = load_prompt(\"./prompt.json\")\n",
    "prompt.format(country=\"Brazil\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is the capital of Brazil'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = load_prompt(\"./prompt.yaml\")\n",
    "prompt.format(country=\"Brazil\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    \n",
      "    You are a role playing assistant.\n",
      "    And you are impersonating a Priate\n",
      "\n",
      "                                     \n",
      "    \n",
      "    This is an example of how you talk:\n",
      "\n",
      "    Human: What is your location?\n",
      "    You: Arrrrg!! That is a secret!!!\n",
      "\n",
      "                              \n",
      "    \n",
      "    Start now!\n",
      "\n",
      "    Human: What is your favorite food?\n",
      "    You:\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts.pipeline import PipelinePromptTemplate\n",
    "\n",
    "intro = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    You are a role playing assistant.\n",
    "    And you are impersonating a {character}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "example = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    This is an example of how you talk:\n",
    "\n",
    "    Human: {example_question}\n",
    "    You: {example_answer}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "start = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    Start now!\n",
    "\n",
    "    Human: {question}\n",
    "    You:\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "final = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    {intro}\n",
    "                                     \n",
    "    {example}\n",
    "                              \n",
    "    {start}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "prompts = [(\"intro\", intro), (\"example\", example), (\"start\", start),]\n",
    "\n",
    "full_prompt = PipelinePromptTemplate(\n",
    "    final_prompt=final,\n",
    "    pipeline_prompts=prompts,\n",
    ")\n",
    "\n",
    "print(full_prompt.format(\n",
    "    character=\"Priate\",\n",
    "    example_question=\"What is your location?\",\n",
    "    example_answer=\"Arrrrg!! That is a secret!!!\",\n",
    "    question = \"What is your favorite food?\"\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arrrrg!! Me favorite food be a good ol' plate of rum-soaked sea biscuits! Aye, nothing beats the taste of salty biscuits washed down with a swig of me finest grog!"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessageChunk(content=\"Arrrrg!! Me favorite food be a good ol' plate of rum-soaked sea biscuits! Aye, nothing beats the taste of salty biscuits washed down with a swig of me finest grog!\")"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = full_prompt | chat\n",
    "\n",
    "chain.invoke({\n",
    "    \"character\":\"Priate\",\n",
    "    \"example_question\":\"What is your location?\",\n",
    "    \"example_answer\":\"Arrrrg!! That is a secret!!!\",\n",
    "    \"question\":\"What is your favorite food?\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Caching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To make an Italian pizza, you will need the following ingredients:\\n\\n- Pizza dough\\n- Tomato sauce\\n- Mozzarella cheese\\n- Fresh basil leaves\\n- Olive oil\\n- Salt and pepper\\n\\nInstructions:\\n\\n1. Preheat your oven to the highest temperature possible (usually around 500°F or 260°C).\\n\\n2. Roll out your pizza dough on a floured surface to your desired thickness.\\n\\n3. Place the rolled out dough on a pizza stone or baking sheet.\\n\\n4. Spread a thin layer of tomato sauce over the dough, leaving a small border around the edges.\\n\\n5. Sprinkle a generous amount of shredded mozzarella cheese over the sauce.\\n\\n6. Tear fresh basil leaves and scatter them over the cheese.\\n\\n7. Drizzle a little olive oil over the top and season with salt and pepper.\\n\\n8. Place the pizza in the preheated oven and bake for about 10-15 minutes, or until the crust is golden brown and the cheese is melted and bubbly.\\n\\n9. Remove the pizza from the oven and let it cool slightly before slicing and serving.\\n\\nEnjoy your delicious Italian pizza!'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.globals import set_llm_cache\n",
    "from langchain.cache import InMemoryCache\n",
    "\n",
    "set_llm_cache(InMemoryCache())\n",
    "\n",
    "chat = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "chat.predict(\"How do you make italia pizza?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To make an Italian pizza, you will need the following ingredients:\\n\\n- Pizza dough\\n- Tomato sauce\\n- Mozzarella cheese\\n- Fresh basil leaves\\n- Olive oil\\n- Salt and pepper\\n\\nInstructions:\\n\\n1. Preheat your oven to the highest temperature possible (usually around 500°F or 260°C).\\n\\n2. Roll out your pizza dough on a floured surface to your desired thickness.\\n\\n3. Place the rolled out dough on a pizza stone or baking sheet.\\n\\n4. Spread a thin layer of tomato sauce over the dough, leaving a small border around the edges.\\n\\n5. Sprinkle a generous amount of shredded mozzarella cheese over the sauce.\\n\\n6. Tear fresh basil leaves and scatter them over the cheese.\\n\\n7. Drizzle a little olive oil over the top and season with salt and pepper.\\n\\n8. Place the pizza in the preheated oven and bake for about 10-15 minutes, or until the crust is golden brown and the cheese is melted and bubbly.\\n\\n9. Remove the pizza from the oven and let it cool slightly before slicing and serving.\\n\\nEnjoy your delicious Italian pizza!'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.predict(\"How do you make italia pizza?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: How do you make italia pizza?\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:llm:ChatOpenAI] [2ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"To make an Italian pizza, you will need the following ingredients:\\n\\n- Pizza dough\\n- Tomato sauce\\n- Mozzarella cheese\\n- Fresh basil leaves\\n- Olive oil\\n- Salt and pepper\\n\\nInstructions:\\n\\n1. Preheat your oven to the highest temperature possible (usually around 500°F or 260°C).\\n\\n2. Roll out your pizza dough on a floured surface to your desired thickness.\\n\\n3. Place the rolled out dough on a pizza stone or baking sheet.\\n\\n4. Spread a thin layer of tomato sauce over the dough, leaving a small border around the edges.\\n\\n5. Sprinkle a generous amount of shredded mozzarella cheese over the sauce.\\n\\n6. Tear fresh basil leaves and scatter them over the cheese.\\n\\n7. Drizzle a little olive oil over the top and season with salt and pepper.\\n\\n8. Place the pizza in the preheated oven and bake for about 10-15 minutes, or until the crust is golden brown and the cheese is melted and bubbly.\\n\\n9. Remove the pizza from the oven and let it cool slightly before slicing and serving.\\n\\nEnjoy your delicious Italian pizza!\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\"\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"To make an Italian pizza, you will need the following ingredients:\\n\\n- Pizza dough\\n- Tomato sauce\\n- Mozzarella cheese\\n- Fresh basil leaves\\n- Olive oil\\n- Salt and pepper\\n\\nInstructions:\\n\\n1. Preheat your oven to the highest temperature possible (usually around 500°F or 260°C).\\n\\n2. Roll out your pizza dough on a floured surface to your desired thickness.\\n\\n3. Place the rolled out dough on a pizza stone or baking sheet.\\n\\n4. Spread a thin layer of tomato sauce over the dough, leaving a small border around the edges.\\n\\n5. Sprinkle a generous amount of shredded mozzarella cheese over the sauce.\\n\\n6. Tear fresh basil leaves and scatter them over the cheese.\\n\\n7. Drizzle a little olive oil over the top and season with salt and pepper.\\n\\n8. Place the pizza in the preheated oven and bake for about 10-15 minutes, or until the crust is golden brown and the cheese is melted and bubbly.\\n\\n9. Remove the pizza from the oven and let it cool slightly before slicing and serving.\\n\\nEnjoy your delicious Italian pizza!\",\n",
      "            \"additional_kwargs\": {}\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'To make an Italian pizza, you will need the following ingredients:\\n\\n- Pizza dough\\n- Tomato sauce\\n- Mozzarella cheese\\n- Fresh basil leaves\\n- Olive oil\\n- Salt and pepper\\n\\nInstructions:\\n\\n1. Preheat your oven to the highest temperature possible (usually around 500°F or 260°C).\\n\\n2. Roll out your pizza dough on a floured surface to your desired thickness.\\n\\n3. Place the rolled out dough on a pizza stone or baking sheet.\\n\\n4. Spread a thin layer of tomato sauce over the dough, leaving a small border around the edges.\\n\\n5. Sprinkle a generous amount of shredded mozzarella cheese over the sauce.\\n\\n6. Tear fresh basil leaves and scatter them over the cheese.\\n\\n7. Drizzle a little olive oil over the top and season with salt and pepper.\\n\\n8. Place the pizza in the preheated oven and bake for about 10-15 minutes, or until the crust is golden brown and the cheese is melted and bubbly.\\n\\n9. Remove the pizza from the oven and let it cool slightly before slicing and serving.\\n\\nEnjoy your delicious Italian pizza!'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.globals import set_debug\n",
    "\n",
    "set_debug(True)\n",
    "\n",
    "chat.predict(\"How do you make italia pizza?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: How do you make italia pizza?\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:llm:ChatOpenAI] [5.42s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"To make an Italian pizza, you will need the following ingredients:\\n\\n- Pizza dough (you can make your own or buy pre-made dough)\\n- Tomato sauce\\n- Mozzarella cheese\\n- Fresh basil leaves\\n- Olive oil\\n- Salt and pepper\\n- Toppings of your choice (such as pepperoni, mushrooms, bell peppers, etc.)\\n\\nHere is a basic recipe for making Italian pizza:\\n\\n1. Preheat your oven to the highest temperature possible (usually around 500°F or higher).\\n\\n2. Roll out the pizza dough on a floured surface to your desired thickness. Place the dough on a pizza stone or baking sheet.\\n\\n3. Spread a thin layer of tomato sauce over the dough, leaving a border around the edges for the crust.\\n\\n4. Sprinkle the mozzarella cheese evenly over the sauce.\\n\\n5. Add your desired toppings on top of the cheese.\\n\\n6. Drizzle a little olive oil over the top of the pizza and season with salt and pepper.\\n\\n7. Bake the pizza in the preheated oven for about 10-15 minutes, or until the crust is golden brown and the cheese is melted and bubbly.\\n\\n8. Remove the pizza from the oven and sprinkle fresh basil leaves on top before serving.\\n\\nEnjoy your homemade Italian pizza!\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\"\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"To make an Italian pizza, you will need the following ingredients:\\n\\n- Pizza dough (you can make your own or buy pre-made dough)\\n- Tomato sauce\\n- Mozzarella cheese\\n- Fresh basil leaves\\n- Olive oil\\n- Salt and pepper\\n- Toppings of your choice (such as pepperoni, mushrooms, bell peppers, etc.)\\n\\nHere is a basic recipe for making Italian pizza:\\n\\n1. Preheat your oven to the highest temperature possible (usually around 500°F or higher).\\n\\n2. Roll out the pizza dough on a floured surface to your desired thickness. Place the dough on a pizza stone or baking sheet.\\n\\n3. Spread a thin layer of tomato sauce over the dough, leaving a border around the edges for the crust.\\n\\n4. Sprinkle the mozzarella cheese evenly over the sauce.\\n\\n5. Add your desired toppings on top of the cheese.\\n\\n6. Drizzle a little olive oil over the top of the pizza and season with salt and pepper.\\n\\n7. Bake the pizza in the preheated oven for about 10-15 minutes, or until the crust is golden brown and the cheese is melted and bubbly.\\n\\n8. Remove the pizza from the oven and sprinkle fresh basil leaves on top before serving.\\n\\nEnjoy your homemade Italian pizza!\",\n",
      "            \"additional_kwargs\": {}\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"prompt_tokens\": 14,\n",
      "      \"completion_tokens\": 257,\n",
      "      \"total_tokens\": 271\n",
      "    },\n",
      "    \"model_name\": \"gpt-3.5-turbo\",\n",
      "    \"system_fingerprint\": null\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'To make an Italian pizza, you will need the following ingredients:\\n\\n- Pizza dough (you can make your own or buy pre-made dough)\\n- Tomato sauce\\n- Mozzarella cheese\\n- Fresh basil leaves\\n- Olive oil\\n- Salt and pepper\\n- Toppings of your choice (such as pepperoni, mushrooms, bell peppers, etc.)\\n\\nHere is a basic recipe for making Italian pizza:\\n\\n1. Preheat your oven to the highest temperature possible (usually around 500°F or higher).\\n\\n2. Roll out the pizza dough on a floured surface to your desired thickness. Place the dough on a pizza stone or baking sheet.\\n\\n3. Spread a thin layer of tomato sauce over the dough, leaving a border around the edges for the crust.\\n\\n4. Sprinkle the mozzarella cheese evenly over the sauce.\\n\\n5. Add your desired toppings on top of the cheese.\\n\\n6. Drizzle a little olive oil over the top of the pizza and season with salt and pepper.\\n\\n7. Bake the pizza in the preheated oven for about 10-15 minutes, or until the crust is golden brown and the cheese is melted and bubbly.\\n\\n8. Remove the pizza from the oven and sprinkle fresh basil leaves on top before serving.\\n\\nEnjoy your homemade Italian pizza!'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.cache import SQLiteCache\n",
    "\n",
    "set_llm_cache(SQLiteCache('cache.db'))\n",
    "\n",
    "chat.predict(\"How do you make italia pizza?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: How do you make italia pizza!?\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:llm:ChatOpenAI] [1ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"To make an Italian pizza, you will need the following ingredients:\\n\\n- Pizza dough (you can make your own or buy pre-made dough)\\n- Tomato sauce\\n- Mozzarella cheese\\n- Fresh basil leaves\\n- Olive oil\\n- Salt and pepper\\n- Toppings of your choice (such as pepperoni, mushrooms, bell peppers, etc.)\\n\\nHere is a basic recipe for making an Italian pizza:\\n\\n1. Preheat your oven to the highest temperature possible (usually around 500°F or 260°C).\\n\\n2. Roll out your pizza dough on a floured surface to your desired thickness.\\n\\n3. Place the dough on a pizza stone or baking sheet lined with parchment paper.\\n\\n4. Spread a thin layer of tomato sauce over the dough, leaving a small border around the edges.\\n\\n5. Sprinkle a generous amount of shredded mozzarella cheese over the sauce.\\n\\n6. Add your desired toppings on top of the cheese.\\n\\n7. Drizzle a little olive oil over the top of the pizza and season with salt and pepper.\\n\\n8. Bake the pizza in the preheated oven for about 10-15 minutes, or until the crust is golden brown and the cheese is bubbly and melted.\\n\\n9. Remove the pizza from the oven and garnish with fresh basil leaves before serving.\\n\\nEnjoy your delicious Italian pizza!\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\"\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"To make an Italian pizza, you will need the following ingredients:\\n\\n- Pizza dough (you can make your own or buy pre-made dough)\\n- Tomato sauce\\n- Mozzarella cheese\\n- Fresh basil leaves\\n- Olive oil\\n- Salt and pepper\\n- Toppings of your choice (such as pepperoni, mushrooms, bell peppers, etc.)\\n\\nHere is a basic recipe for making an Italian pizza:\\n\\n1. Preheat your oven to the highest temperature possible (usually around 500°F or 260°C).\\n\\n2. Roll out your pizza dough on a floured surface to your desired thickness.\\n\\n3. Place the dough on a pizza stone or baking sheet lined with parchment paper.\\n\\n4. Spread a thin layer of tomato sauce over the dough, leaving a small border around the edges.\\n\\n5. Sprinkle a generous amount of shredded mozzarella cheese over the sauce.\\n\\n6. Add your desired toppings on top of the cheese.\\n\\n7. Drizzle a little olive oil over the top of the pizza and season with salt and pepper.\\n\\n8. Bake the pizza in the preheated oven for about 10-15 minutes, or until the crust is golden brown and the cheese is bubbly and melted.\\n\\n9. Remove the pizza from the oven and garnish with fresh basil leaves before serving.\\n\\nEnjoy your delicious Italian pizza!\",\n",
      "            \"additional_kwargs\": {}\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'To make an Italian pizza, you will need the following ingredients:\\n\\n- Pizza dough (you can make your own or buy pre-made dough)\\n- Tomato sauce\\n- Mozzarella cheese\\n- Fresh basil leaves\\n- Olive oil\\n- Salt and pepper\\n- Toppings of your choice (such as pepperoni, mushrooms, bell peppers, etc.)\\n\\nHere is a basic recipe for making an Italian pizza:\\n\\n1. Preheat your oven to the highest temperature possible (usually around 500°F or 260°C).\\n\\n2. Roll out your pizza dough on a floured surface to your desired thickness.\\n\\n3. Place the dough on a pizza stone or baking sheet lined with parchment paper.\\n\\n4. Spread a thin layer of tomato sauce over the dough, leaving a small border around the edges.\\n\\n5. Sprinkle a generous amount of shredded mozzarella cheese over the sauce.\\n\\n6. Add your desired toppings on top of the cheese.\\n\\n7. Drizzle a little olive oil over the top of the pizza and season with salt and pepper.\\n\\n8. Bake the pizza in the preheated oven for about 10-15 minutes, or until the crust is golden brown and the cheese is bubbly and melted.\\n\\n9. Remove the pizza from the oven and garnish with fresh basil leaves before serving.\\n\\nEnjoy your delicious Italian pizza!'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.predict(\"How do you make italia pizza!?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6 Serialization\n",
    "\n",
    "**4.6.1 get_openai_callback**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: What is the recipe for soju\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:llm:ChatOpenAI] [4.03s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"Ingredients:\\n- 1 cup of rice\\n- 1 cup of water\\n- 1 tablespoon of nuruk (fermentation starter)\\n- 1 tablespoon of yeast\\n\\nInstructions:\\n1. Rinse the rice thoroughly and soak it in water for at least 1 hour.\\n2. Drain the rice and steam it until it is fully cooked.\\n3. Let the rice cool down to room temperature.\\n4. In a large bowl, mix the nuruk and yeast with the cooked rice.\\n5. Cover the bowl with a clean cloth and let it ferment for 3-4 days in a warm place.\\n6. After fermentation, strain the mixture through a cheesecloth to separate the liquid from the solids.\\n7. Transfer the liquid to a clean container and let it sit for another 2-3 days to allow the flavors to develop.\\n8. Your homemade soju is now ready to be enjoyed! Serve chilled and enjoy responsibly.\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\"\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"Ingredients:\\n- 1 cup of rice\\n- 1 cup of water\\n- 1 tablespoon of nuruk (fermentation starter)\\n- 1 tablespoon of yeast\\n\\nInstructions:\\n1. Rinse the rice thoroughly and soak it in water for at least 1 hour.\\n2. Drain the rice and steam it until it is fully cooked.\\n3. Let the rice cool down to room temperature.\\n4. In a large bowl, mix the nuruk and yeast with the cooked rice.\\n5. Cover the bowl with a clean cloth and let it ferment for 3-4 days in a warm place.\\n6. After fermentation, strain the mixture through a cheesecloth to separate the liquid from the solids.\\n7. Transfer the liquid to a clean container and let it sit for another 2-3 days to allow the flavors to develop.\\n8. Your homemade soju is now ready to be enjoyed! Serve chilled and enjoy responsibly.\",\n",
      "            \"additional_kwargs\": {}\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"prompt_tokens\": 14,\n",
      "      \"completion_tokens\": 190,\n",
      "      \"total_tokens\": 204\n",
      "    },\n",
      "    \"model_name\": \"gpt-3.5-turbo\",\n",
      "    \"system_fingerprint\": null\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "Tokens Used: 204\n",
      "\tPrompt Tokens: 14\n",
      "\tCompletion Tokens: 190\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.00040100000000000004\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.callbacks import get_openai_callback\n",
    "\n",
    "with get_openai_callback() as usage:\n",
    "    chat.predict(\"What is the recipe for soju\")\n",
    "    print(usage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.6.2 Serialization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.llms.openai import OpenAI\n",
    "\n",
    "chat = OpenAI(\n",
    "    temperature=0.1,\n",
    "    max_tokens=450,\n",
    "    model='gpt-3.5-turbo-16k',\n",
    ")\n",
    "\n",
    "chat.save(\"model.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mOpenAIChat\u001b[0m\n",
      "Params: {'model_name': 'gpt-3.5-turbo-16k', 'temperature': 0.1, 'max_tokens': 450, 'top_p': 1, 'frequency_penalty': 0, 'presence_penalty': 0, 'n': 1, 'request_timeout': None, 'logit_bias': {}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sigi/hanwha_project/langchain_study/kang/env/lib/python3.11/site-packages/langchain/llms/openai.py:216: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n",
      "/Users/sigi/hanwha_project/langchain_study/kang/env/lib/python3.11/site-packages/langchain/llms/openai.py:811: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms.loading import load_llm\n",
    "chat = load_llm(\"model.json\")\n",
    "print(chat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.0 ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content='Hi!'), AIMessage(content='How are you?')]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory(return_messages=True)\n",
    "\n",
    "memory.save_context({\"input\": \"Hi!\"}, {\"output\":\"How are you?\"})\n",
    "\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content='Hi!'),\n",
       "  AIMessage(content='How are you?'),\n",
       "  HumanMessage(content='Hi!'),\n",
       "  AIMessage(content='How are you?')]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.save_context({\"input\": \"Hi!\"}, {\"output\":\"How are you?\"})\n",
    "\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 ConversationBufferWindowMemory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content='1'),\n",
       "  AIMessage(content='1'),\n",
       "  HumanMessage(content='2'),\n",
       "  AIMessage(content='2'),\n",
       "  HumanMessage(content='3'),\n",
       "  AIMessage(content='3'),\n",
       "  HumanMessage(content='4'),\n",
       "  AIMessage(content='4')]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "\n",
    "memory = ConversationBufferWindowMemory(\n",
    "    return_messages=True,\n",
    "    k=4\n",
    ")\n",
    "\n",
    "def add_message(input, output):\n",
    "    memory.save_context({\"input\": input}, {\"output\": output})\n",
    "\n",
    "add_message(1,1)\n",
    "add_message(2,2)\n",
    "add_message(3,3)\n",
    "add_message(4,4)\n",
    "\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content='2'),\n",
       "  AIMessage(content='2'),\n",
       "  HumanMessage(content='3'),\n",
       "  AIMessage(content='3'),\n",
       "  HumanMessage(content='4'),\n",
       "  AIMessage(content='4'),\n",
       "  HumanMessage(content='5'),\n",
       "  AIMessage(content='5')]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_message(5,5)\n",
    "\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 ConversationSummaryMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryMemory\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "memory = ConversationSummaryMemory(llm=llm)\n",
    "\n",
    "def add_message(input, output):\n",
    "    memory.save_context({\"input\": input}, {\"output\": output})\n",
    "\n",
    "\n",
    "def get_history():\n",
    "    return memory.load_memory_variables({})\n",
    "\n",
    "\n",
    "add_message(\"Hi I'm Nicolas, I live in South Korea\", \"Wow that is so cool!\")\n",
    "add_message(\"South Kddorea is so pretty\", \"I wish I could go!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Nicolas from South Korea introduces himself to the AI, who responds enthusiastically. The human mentions how pretty South Korea is, prompting the AI to express a desire to visit.'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_history()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 ConversationSummaryBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content=\"Hi I'm Nicolas, I live in South Korea\"),\n",
       "  AIMessage(content='Wow that is so cool!')]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(\n",
    "    llm=llm,\n",
    "    max_token_limit=50,\n",
    "    return_messages=True,\n",
    ")\n",
    "\n",
    "\n",
    "def add_message(input, output):\n",
    "    memory.save_context({\"input\": input}, {\"output\": output})\n",
    "\n",
    "\n",
    "def get_history():\n",
    "    return memory.load_memory_variables({})\n",
    "\n",
    "\n",
    "add_message(\"Hi I'm Nicolas, I live in South Korea\", \"Wow that is so cool!\")\n",
    "get_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content=\"Hi I'm Nicolas, I live in South Korea\"),\n",
       "  AIMessage(content='Wow that is so cool!'),\n",
       "  HumanMessage(content='South Korea is so pretty'),\n",
       "  AIMessage(content='I wish I could go!!!')]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_message(\"South Korea is so pretty\", \"I wish I could go!!!\")\n",
    "get_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [SystemMessage(content=\"The human introduces himself as Nicolas from South Korea. The AI responds by expressing admiration for Nicolas's location.\"),\n",
       "  HumanMessage(content='South Korea is so pretty'),\n",
       "  AIMessage(content='I wish I could go!!!'),\n",
       "  HumanMessage(content='How far is Korea from Argentina?'),\n",
       "  AIMessage(content=\"I don't know! Super far!\")]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_message(\"How far is Korea from Argentina?\", \"I don't know! Super far!\")\n",
    "get_history()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 ConversationKGMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [SystemMessage(content='On Nicolas: Nicolas lives in South Korea.')]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ConversationKGMemory\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "memory = ConversationKGMemory(\n",
    "    llm=llm,\n",
    "    return_messages=True,\n",
    ")\n",
    "\n",
    "def add_message(input, output):\n",
    "    memory.save_context({\"input\": input}, {\"output\": output})\n",
    "\n",
    "add_message(\"Hi I'm Nicolas, I live in South Korea\", \"Wow that is so cool!\")\n",
    "memory.load_memory_variables({\"input\": \"who is Nicolas\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [SystemMessage(content='On Nicolas: Nicolas lives in South Korea. Nicolas likes kimchi.')]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_message(\"Nicolas likes kimchi\", \"Wow that is so cool!\")\n",
    "memory.load_memory_variables({\"inputs\": \"what does nicolas like\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5 Memory on LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "    You are a chatbot that helps people with their daily life.\n",
      "\n",
      "    \n",
      "    Human: My name is Nico\n",
      "    AI:\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Nice to meet you, Nico! How can I assist you today?'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(\n",
    "    llm=llm,\n",
    "    max_token_limit=50,\n",
    "    memory_key=\"chat_history\",\n",
    ")\n",
    "\n",
    "template = \"\"\"\n",
    "    You are a chatbot that helps people with their daily life.\n",
    "\n",
    "    {chat_history}\n",
    "    Human: {question}\n",
    "    AI:\n",
    "\"\"\"\n",
    "\n",
    "chain = LLMChain(\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    "    prompt=PromptTemplate.from_template(template),\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "chain.predict(question=\"My name is Nico\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "    You are a chatbot that helps people with their daily life.\n",
      "\n",
      "    Human: My name is Nico\n",
      "AI: Nice to meet you, Nico! How can I assist you today?\n",
      "    Human: I`m living in seoul.\n",
      "    AI:\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"That's great to hear! How are you finding living in Seoul? Is there anything specific you need help with in your daily life there?\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.predict(question=\"I`m living in seoul.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "    You are a chatbot that helps people with their daily life.\n",
      "\n",
      "    System: The human introduces themselves as Nico. The AI responds by saying it's nice to meet Nico and asks how it can assist them today.\n",
      "Human: I`m living in seoul.\n",
      "AI: That's great to hear! How are you finding living in Seoul? Is there anything specific you need help with in your daily life there?\n",
      "    Human: what is my name?\n",
      "    AI:\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Your name is Nico.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.predict(question=\"what is my name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'chat_history': 'System: Nico introduces themselves and mentions they are living in Seoul. The AI responds positively and asks how they are finding living in Seoul, offering assistance with anything specific in their daily life there.\\nHuman: what is my name?\\nAI: Your name is Nico.'}\n"
     ]
    }
   ],
   "source": [
    "print(memory.load_memory_variables({}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.6 Chat Based Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a chatbot that helps people with their daily life.\n",
      "Human: My name is Nico\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Nice to meet you, Nico! How can I assist you today?'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(\n",
    "    llm=llm,\n",
    "    max_token_limit=50,\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True,\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a chatbot that helps people with their daily life.\"),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"human\", \"{question}\"),\n",
    "])\n",
    "\n",
    "chain = LLMChain(\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    "    prompt=prompt,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "chain.predict(question=\"My name is Nico\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a chatbot that helps people with their daily life.\n",
      "Human: My name is Nico\n",
      "AI: Nice to meet you, Nico! How can I assist you today?\n",
      "Human: I`m living in seoul.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"That's great! How can I help you with living in Seoul? Do you have any specific questions or need information about the city?\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.predict(question=\"I`m living in seoul.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a chatbot that helps people with their daily life.\n",
      "System: The human introduces themselves as Nico. The AI responds by saying \"Nice to meet you, Nico! How can I assist you today?\"\n",
      "Human: I`m living in seoul.\n",
      "AI: That's great! How can I help you with living in Seoul? Do you have any specific questions or need information about the city?\n",
      "Human: what is my name?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Your name is Nico. How can I assist you further, Nico?'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.predict(question=\"what is my name?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.7 LCEL Based Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: {'question': 'My name is Nico'}\n",
      "history:  []\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Nice to meet you, Nico! How can I assist you today?')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(\n",
    "    llm=llm,\n",
    "    max_token_limit=50,\n",
    "    return_messages=True,\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a chatbot that helps people with their daily life.\"),\n",
    "    MessagesPlaceholder(variable_name=\"history\"),\n",
    "    (\"human\", \"{question}\"),\n",
    "])\n",
    "\n",
    "def load_memory(input):\n",
    "    history = memory.load_memory_variables({})['history']\n",
    "    print(\"input:\" ,input)\n",
    "    print(\"history: \", history)\n",
    "    return history\n",
    "\n",
    "chain = RunnablePassthrough.assign(history=load_memory) | prompt | llm\n",
    "\n",
    "chain.invoke({\"question\": \"My name is Nico\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: {'question': 'My name is Nico'}\n",
      "history:  []\n",
      "Nice to meet you, Nico! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "def invoke_chain(question):\n",
    "    result = chain.invoke({\"question\": question})\n",
    "    memory.save_context(\n",
    "        {\"input\": question},\n",
    "        {\"output\": result.content},\n",
    "    )\n",
    "    print(result.content)\n",
    "\n",
    "invoke_chain(\"My name is Nico\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: {'question': 'What is my name?'}\n",
      "history:  [HumanMessage(content='My name is Nico'), AIMessage(content='Nice to meet you, Nico! How can I assist you today?')]\n",
      "Your name is Nico. How can I help you today, Nico?\n"
     ]
    }
   ],
   "source": [
    "invoke_chain(\"What is my name?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Data Loaders and Splitters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6.1.1 UnstructuredFileLoader**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import UnstructuredFileLoader\n",
    "\n",
    "loader = UnstructuredFileLoader(\"./files/chapter_one.txt\")\n",
    "\n",
    "len(loader.load())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6.1.2 RecursiveCharacterTextSplitter**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='Part 1, Chapter 1\\n\\nPart One\\n\\n1\\n\\nIt was a bright cold day in April, and the clocks were striking thirteen. Winston Smith, his chin nuzzled into his' metadata={'source': './files/chapter_one.txt'}\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "spliter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=200,\n",
    ")\n",
    "loader = UnstructuredFileLoader(\"./files/chapter_one.txt\")\n",
    "split_docs = loader.load_and_split(text_splitter=spliter)\n",
    "print(split_docs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='breast in an effort to escape the vile wind, slipped quickly\\n\\nthrough the glass doors of Victory Mansions, though not\\n\\nquickly enough to prevent a swirl of gritty dust from entering along with him.' metadata={'source': './files/chapter_one.txt'}\n"
     ]
    }
   ],
   "source": [
    "spliter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=200,\n",
    "    chunk_overlap=50,\n",
    ")\n",
    "loader = UnstructuredFileLoader(\"./files/chapter_one.txt\")\n",
    "split_docs = loader.load_and_split(text_splitter=spliter)\n",
    "print(split_docs[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6.1.3 CharacterTextSplitter**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='breast in an effort to escape the vile wind, slipped quickly\\n\\nthrough the glass doors of Victory Mansions, though not\\n\\nquickly enough to prevent a swirl of gritty dust from entering along with him.' metadata={'source': './files/chapter_one.txt'}\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "spliter = CharacterTextSplitter(\n",
    "    separator=\"\\n\\n\",\n",
    "    chunk_size=200,\n",
    "    chunk_overlap=50,\n",
    ")\n",
    "loader = UnstructuredFileLoader(\"./files/chapter_one.txt\")\n",
    "split_docs = loader.load_and_split(text_splitter=spliter)\n",
    "print(split_docs[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "⛔️ **CharacterTextSplitter는 내 생각과 다르게 분할한다!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 17, which is longer than the specified 12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "Chunk 1:\n",
      "Part 1, Chapter 1\n",
      "\n",
      "Chunk 2:\n",
      "Part One\n",
      "\n",
      "Chunk 3:\n",
      "1\n",
      "\n",
      "Chunk 4:\n",
      "It was a bright cold day in April, and the clocks were striking thirteen. Winston Smith, his chin nuzzled into his\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "# \"\\n\\n\"를 구분자로 설정하여 텍스트를 분할\n",
    "splitter = CharacterTextSplitter(\n",
    "    separator=r\"\\n\\n\",\n",
    "    is_separator_regex=True,\n",
    "    chunk_size=12,\n",
    "    chunk_overlap=0,\n",
    ")\n",
    "\n",
    "# 예제 텍스트 설정\n",
    "text = \"\"\"Part 1, Chapter 1\\n\\nPart One\\n\\n1\\n\\nIt was a bright cold day in April, and the clocks were striking thirteen. Winston Smith, his chin nuzzled into his\"\"\"\n",
    "\n",
    "# 텍스트 분할 수행\n",
    "split_texts = splitter.split_text(text)\n",
    "\n",
    "# 분할된 청크의 수 출력\n",
    "print(len(split_texts))\n",
    "\n",
    "# 분할된 청크 출력\n",
    "for i, chunk in enumerate(split_texts):\n",
    "    print(f\"Chunk {i + 1}:\\n{chunk}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 17, which is longer than the specified 13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "Chunk 1:\n",
      "Part 1, Chapter 1\n",
      "\n",
      "Chunk 2:\n",
      "Part One\\n\\n1\n",
      "\n",
      "Chunk 3:\n",
      "It was a bright cold day in April, and the clocks were striking thirteen. Winston Smith, his chin nuzzled into his\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "# \"\\n\\n\"를 구분자로 설정하여 텍스트를 분할\n",
    "splitter = CharacterTextSplitter(\n",
    "    separator=r\"\\n\\n\",\n",
    "    is_separator_regex=True,\n",
    "    chunk_size=13,\n",
    "    chunk_overlap=0,\n",
    ")\n",
    "\n",
    "# 예제 텍스트 설정\n",
    "text = \"\"\"Part 1, Chapter 1\\n\\nPart One\\n\\n1\\n\\nIt was a bright cold day in April, and the clocks were striking thirteen. Winston Smith, his chin nuzzled into his\"\"\"\n",
    "\n",
    "# 텍스트 분할 수행\n",
    "split_texts = splitter.split_text(text)\n",
    "\n",
    "# 분할된 청크의 수 출력\n",
    "print(len(split_texts))\n",
    "\n",
    "# 분할된 청크 출력\n",
    "for i, chunk in enumerate(split_texts):\n",
    "    print(f\"Chunk {i + 1}:\\n{chunk}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='no use trying the lift. Even at the best of times it was seldom working, and at present the electric current was cut\\n\\noff during daylight hours. It was part of the economy drive\\n\\nin preparation for Hate Week. The flat was seven flights up,\\n\\nand Winston, who was thirty-nine and had a varicose ulcer\\n\\nabove his right ankle, went slowly, resting several times on\\n\\nthe way. On each landing, opposite the lift-shaft, the poster\\n\\nwith the enormous face gazed from the wall. It was one of\\n\\nthose pictures which are so contrived that the eyes follow\\n\\nyou about when you move. BIG BROTHER IS WATCHING\\n\\nYOU, the caption beneath it ran.\\n\\nInside the flat a fruity voice was reading out a list of fig\\n\\nures which had something to do with the production of\\n\\npig-iron. The voice came from an oblong metal plaque like' metadata={'source': './files/chapter_one.txt'}\n"
     ]
    }
   ],
   "source": [
    "spliter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "    separator=\"\\n\\n\",\n",
    "    chunk_size=200,\n",
    "    chunk_overlap=50,\n",
    ")\n",
    "loader = UnstructuredFileLoader(\"./files/chapter_one.txt\")\n",
    "split_docs = loader.load_and_split(text_splitter=spliter)\n",
    "print(split_docs[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 Vector Store\n",
    "\n",
    "**6.4.1 embedding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.03091332069063776,\n",
       " -0.02041421168270496,\n",
       " -0.019505760491086016,\n",
       " -0.04178878834208551,\n",
       " -0.024813714510781345,\n",
       " 0.024307577923883064,\n",
       " -0.017974369955820486,\n",
       " -0.01770183515712837,\n",
       " -0.0065019203189157744,\n",
       " -0.015910886872450965,\n",
       " 0.025890880381560014,\n",
       " -0.006949656924423819,\n",
       " -0.017909480984128822,\n",
       " -0.011848808746080972,\n",
       " 0.011465960646603284,\n",
       " 0.016481912431040906,\n",
       " 0.03875196137011493,\n",
       " 0.0005187098496184129,\n",
       " 0.032211107575051905,\n",
       " -0.00870167126729266,\n",
       " -0.01963553843446934,\n",
       " -0.004905640346297275,\n",
       " -0.009298654649733536,\n",
       " -0.014327584414774013,\n",
       " -0.022867032321514904,\n",
       " 0.002483642527834438,\n",
       " 0.010051371936763446,\n",
       " -0.011764452337823722,\n",
       " 0.0026069326450696003,\n",
       " -0.026020658324943338,\n",
       " 0.014535230241774468,\n",
       " 0.0006987779917067696,\n",
       " -0.035767050045846224,\n",
       " -0.014963500807700843,\n",
       " -0.009486833971491013,\n",
       " -0.02474882553908968,\n",
       " 0.006988590866232384,\n",
       " -0.021115018909968676,\n",
       " 0.019181313769982482,\n",
       " -0.005687557856852956,\n",
       " 0.0061288059377208794,\n",
       " -0.0007223004069264543,\n",
       " 0.0014072893524503538,\n",
       " -0.014392474317788288,\n",
       " -0.023022766226103938,\n",
       " -0.006089872461573621,\n",
       " 0.0009684746429454653,\n",
       " 0.0040718113789914795,\n",
       " -0.012361434788941986,\n",
       " 0.01984318612411502,\n",
       " 0.0158979079605255,\n",
       " 0.007066458284188207,\n",
       " -0.02974531174960694,\n",
       " -0.011388093694308767,\n",
       " -0.020063809000395717,\n",
       " -0.007630996249460641,\n",
       " -0.015132213624215345,\n",
       " 0.011238848314359853,\n",
       " -0.010551019999021605,\n",
       " -0.02265938649451445,\n",
       " -0.010771643806624914,\n",
       " 0.005499378535095478,\n",
       " -0.004879684385091565,\n",
       " 0.00606067223804785,\n",
       " 0.010421241124315668,\n",
       " -0.008461580954446374,\n",
       " 0.023567837686133394,\n",
       " -0.0010195750923232267,\n",
       " 0.004438436304223641,\n",
       " 0.0007908398140124807,\n",
       " 0.021426486719146747,\n",
       " 0.033820365993934565,\n",
       " -0.004989996754554526,\n",
       " -0.014249717462479496,\n",
       " 0.01206294402904416,\n",
       " -0.007326015567938775,\n",
       " -0.0035656738607705877,\n",
       " -0.0012174877831175191,\n",
       " -0.00618720638477242,\n",
       " -0.006891256477372278,\n",
       " 0.025138163094530104,\n",
       " -0.03138052426705008,\n",
       " -0.016001731805348335,\n",
       " 0.01748121041820245,\n",
       " 0.00831233464317485,\n",
       " 0.0167933821028642,\n",
       " -0.0050775974251318365,\n",
       " 0.012854594326560023,\n",
       " -0.01565132912303909,\n",
       " -0.03187368566731335,\n",
       " 0.006398096939754241,\n",
       " 0.022996812127543453,\n",
       " 0.013574867127744103,\n",
       " 0.013821446896553121,\n",
       " -0.011083113478448207,\n",
       " 0.01832477263812973,\n",
       " -0.01156978356010351,\n",
       " 0.018493485454644232,\n",
       " -0.007403882985894598,\n",
       " 0.006284540773632526,\n",
       " 0.0008086844209260796,\n",
       " 0.008870384083807161,\n",
       " 0.0013967448014181973,\n",
       " -0.0055026227974155385,\n",
       " -0.027902451542518115,\n",
       " -0.020647813470911124,\n",
       " -0.017416321446510785,\n",
       " -0.013821446896553121,\n",
       " 0.01680636101478967,\n",
       " -0.0015021900789091078,\n",
       " -0.0029102904969394764,\n",
       " 0.03651976733287614,\n",
       " 0.005548045729525531,\n",
       " -0.034261615471786404,\n",
       " -0.010401774619072691,\n",
       " -0.007955443436225482,\n",
       " 0.003220137571941433,\n",
       " -0.0034066947625388806,\n",
       " -0.012205699953030339,\n",
       " -0.023204457954543907,\n",
       " 0.004545503945705235,\n",
       " 0.000205415571278402,\n",
       " 0.0155085722677303,\n",
       " 0.003345049820336626,\n",
       " 0.01569026213352504,\n",
       " 0.008072244330328564,\n",
       " -0.02404802017447119,\n",
       " -0.0052430655136649715,\n",
       " 0.007579084327049221,\n",
       " 0.005009463259797502,\n",
       " 0.04817390636991429,\n",
       " 0.011751474357220867,\n",
       " 0.005191153591253552,\n",
       " -0.007209214673835692,\n",
       " -0.03356081010716792,\n",
       " 0.03540367031425674,\n",
       " -0.024891582394398475,\n",
       " 0.023074678148515358,\n",
       " -0.02397015229085406,\n",
       " -0.032392801166137096,\n",
       " -0.005661601895647246,\n",
       " 0.038284757793702606,\n",
       " -7.472422596707446e-05,\n",
       " -0.01740334253458532,\n",
       " -0.013821446896553121,\n",
       " -0.013445088253038166,\n",
       " 0.015106257663009635,\n",
       " -0.0029313795990037893,\n",
       " -0.001494890023027665,\n",
       " -0.0021056617531594523,\n",
       " 0.0015938464266324745,\n",
       " 0.0018509707464736496,\n",
       " 0.020102743873526892,\n",
       " -0.000546693358358834,\n",
       " 0.0293040622717551,\n",
       " 0.020673769432116833,\n",
       " -0.012945440190780007,\n",
       " -0.010765155281984792,\n",
       " -0.010914400661933705,\n",
       " -0.0087600717143442,\n",
       " -0.0008090900119237504,\n",
       " -0.003038447240485383,\n",
       " 0.02380143947433956,\n",
       " -0.010628886951316122,\n",
       " -0.00376034193999884,\n",
       " 0.017662900283997193,\n",
       " 0.012277078380684736,\n",
       " 0.02735738008248866,\n",
       " 0.012841616345957168,\n",
       " -0.001837992882286121,\n",
       " 0.013354243320140794,\n",
       " 0.01963553843446934,\n",
       " -0.030394205191814013,\n",
       " 0.0053176882036394275,\n",
       " 0.0004643649341937692,\n",
       " 0.011050668992602377,\n",
       " 0.01576813001714217,\n",
       " 0.013626779050155522,\n",
       " -0.030420161153019723,\n",
       " -0.04404694020317525,\n",
       " -0.015313903490010088,\n",
       " 0.017351432474819125,\n",
       " 0.03273022307387565,\n",
       " 0.029589575982372683,\n",
       " -0.009233764746719261,\n",
       " 0.014314606434171158,\n",
       " 0.029823177770578847,\n",
       " 0.004863462142168649,\n",
       " 0.0166246692863497,\n",
       " -0.020258477778115926,\n",
       " 0.0155085722677303,\n",
       " 0.02899259446257703,\n",
       " 0.016858271074555863,\n",
       " -0.006527875814460178,\n",
       " -0.7010134146395053,\n",
       " -0.031198834401255343,\n",
       " -0.004545503945705235,\n",
       " -0.0019061268147898033,\n",
       " 0.020725681354528253,\n",
       " 0.043112533050350586,\n",
       " 0.026760398562693008,\n",
       " 0.021452442680352457,\n",
       " -0.01825988366643807,\n",
       " 0.015962798794862385,\n",
       " -0.007864597572005498,\n",
       " -0.004506570469557976,\n",
       " 0.008247445671483188,\n",
       " -0.014859677894200615,\n",
       " 0.005625913147481354,\n",
       " 0.007423349956798881,\n",
       " -0.00034290003465578897,\n",
       " -0.0074947283844532765,\n",
       " -0.011238848314359853,\n",
       " 0.002081328155944426,\n",
       " -0.004146434068965936,\n",
       " -0.003916076543079833,\n",
       " -0.023399124869618895,\n",
       " 0.020777593276939673,\n",
       " 0.009292165193770801,\n",
       " -0.0054864005544926235,\n",
       " -0.0022484183756375908,\n",
       " -0.009298654649733536,\n",
       " -0.01954469350157197,\n",
       " 0.010239551258520925,\n",
       " -0.013717623983052894,\n",
       " 0.01198507614542703,\n",
       " 0.012017520631272862,\n",
       " -0.010297951705572465,\n",
       " 0.05985400323080337,\n",
       " 0.00512950888188195,\n",
       " -0.004292435186594789,\n",
       " 0.02038825572149925,\n",
       " 0.006495431328614347,\n",
       " 0.04916022544515036,\n",
       " -0.000711350264896627,\n",
       " -0.019337047674571516,\n",
       " 0.005252798766286459,\n",
       " 0.006274807055349732,\n",
       " 0.005768669537128839,\n",
       " 0.01687124998648133,\n",
       " -0.009078029910807615,\n",
       " -0.0015313904188502046,\n",
       " 0.009512789001374112,\n",
       " -0.0009911859343774716,\n",
       " 0.010804089223793356,\n",
       " -0.0067030771556148006,\n",
       " -0.012328990303096156,\n",
       " 0.01884388813695348,\n",
       " 0.009324609679616633,\n",
       " -0.0027302225294741096,\n",
       " 0.021945602217970494,\n",
       " -0.024385445807500194,\n",
       " -0.005960093586867684,\n",
       " 0.02397015229085406,\n",
       " 0.0003869031945471117,\n",
       " 0.0030887365660754664,\n",
       " -0.014158871598259511,\n",
       " -0.0192332256923939,\n",
       " -0.013977181732464768,\n",
       " 0.019778295289778133,\n",
       " -0.02195858112989596,\n",
       " -0.009603634865594094,\n",
       " -0.0008897962176172901,\n",
       " -0.005937382353643341,\n",
       " -0.013081707590126066,\n",
       " 0.019337047674571516,\n",
       " -0.02743524796610579,\n",
       " -0.016352134487657582,\n",
       " 0.002018061082582141,\n",
       " 0.023892286269882157,\n",
       " 0.012393879274787818,\n",
       " -0.0060704054906693386,\n",
       " -0.00914291981382189,\n",
       " 0.010070838442006423,\n",
       " 0.0013204997474530575,\n",
       " -0.002413886464170726,\n",
       " -0.005505867525396906,\n",
       " -0.011498406063771727,\n",
       " 0.02419077702977998,\n",
       " -0.026487861901355665,\n",
       " -0.03363867612813982,\n",
       " 0.014366518356582578,\n",
       " -0.0067290331168205104,\n",
       " -0.0025631320769502917,\n",
       " 0.00548964528247399,\n",
       " 0.03584491606681813,\n",
       " 0.013062241084883089,\n",
       " -0.0203493227110133,\n",
       " 0.006167739413868138,\n",
       " 0.00945438855432257,\n",
       " -0.0205180355275278,\n",
       " 0.002926512972693045,\n",
       " -0.003242848805165776,\n",
       " -0.012711837471251231,\n",
       " -0.007877575552608353,\n",
       " 0.0029394907204652473,\n",
       " -0.0016603581115607997,\n",
       " -0.005638890662422903,\n",
       " 0.01670253716996683,\n",
       " -0.0039030987953076316,\n",
       " -0.014444385308877095,\n",
       " 0.039842104290173846,\n",
       " 0.027513115849722918,\n",
       " -0.02042719059463043,\n",
       " -0.0024803982655143774,\n",
       " -0.001167198457527436,\n",
       " -0.007819175105556811,\n",
       " 0.0054085331365368,\n",
       " 0.008240956215520453,\n",
       " -0.03301573678449323,\n",
       " -0.0121213444760957,\n",
       " 0.03156221413284483,\n",
       " 0.021608178447586713,\n",
       " -0.015210080576509862,\n",
       " 0.005330666184242282,\n",
       " -0.003666252279120101,\n",
       " 0.021037151026351546,\n",
       " -0.016481912431040906,\n",
       " 0.001456767496045095,\n",
       " 0.018584330387541603,\n",
       " -0.010447197085521378,\n",
       " -0.003562429365619874,\n",
       " -0.03164008387910718,\n",
       " 0.007890553533211208,\n",
       " 0.013899313848847638,\n",
       " -0.011388093694308767,\n",
       " 0.017792680090025742,\n",
       " -0.02056994744993922,\n",
       " 0.014210783520670931,\n",
       " -0.005976315829790599,\n",
       " 0.0012239767734189466,\n",
       " -0.010797599767830623,\n",
       " -0.008169578719188669,\n",
       " -0.005165198095709148,\n",
       " -0.002081328155944426,\n",
       " 0.0046915050633340874,\n",
       " 0.0001128467602256023,\n",
       " -0.004626615625981119,\n",
       " 0.0019872384950656873,\n",
       " -0.03223706539890284,\n",
       " -0.01970042926880623,\n",
       " -0.0050905754057346915,\n",
       " -0.012698860421970989,\n",
       " 0.0049478185504259,\n",
       " 0.0006780944806401277,\n",
       " -0.0018574597367750768,\n",
       " -0.010849511690242043,\n",
       " 0.018778999165261816,\n",
       " 0.035507490433789125,\n",
       " -0.022049426062793333,\n",
       " -0.003504028918568333,\n",
       " -0.021283729863837954,\n",
       " -0.011303737286051515,\n",
       " -2.1443926884664023e-05,\n",
       " 0.0034553617241382803,\n",
       " 0.02249067367799995,\n",
       " -0.014937544846495133,\n",
       " 0.002027794335203629,\n",
       " 0.0017763479400838664,\n",
       " -0.027616937831900532,\n",
       " -0.0016506246261086587,\n",
       " 0.02341210378154436,\n",
       " 0.0030546694834082985,\n",
       " -0.038310715617553545,\n",
       " 0.017221652668790575,\n",
       " -0.015833018988833835,\n",
       " -0.006164495151548078,\n",
       " 0.0026945333156469116,\n",
       " 0.017779701178100273,\n",
       " 0.006167739413868138,\n",
       " -0.00744930591800459,\n",
       " 0.007462283432946139,\n",
       " -0.0015557238996499047,\n",
       " -0.03291191666496084,\n",
       " 0.010771643806624914,\n",
       " 0.002152706583598822,\n",
       " -0.010667820893124687,\n",
       " 0.010129238889057963,\n",
       " 0.02105012807563179,\n",
       " 0.008052776893762976,\n",
       " 0.008870384083807161,\n",
       " 0.02560536667094243,\n",
       " -0.01273130490781682,\n",
       " 0.01092737864253656,\n",
       " 0.0075077063650561306,\n",
       " 0.02054399148873351,\n",
       " -0.017143784785173446,\n",
       " -0.0012961662666533577,\n",
       " 0.008208511729674623,\n",
       " 0.011329693247257225,\n",
       " 0.002527443095953747,\n",
       " 0.002790245107685681,\n",
       " 0.00920132026087343,\n",
       " 0.023892286269882157,\n",
       " 0.04207430205270309,\n",
       " 0.009441410573719715,\n",
       " 0.03433948149275831,\n",
       " -0.011193424916588555,\n",
       " -0.009700968323131588,\n",
       " -0.02626723902507497,\n",
       " 0.0011761207609842356,\n",
       " -0.005703780099775871,\n",
       " 0.02054399148873351,\n",
       " 0.016248310642834742,\n",
       " -0.005200887309536346,\n",
       " -0.015249014518318426,\n",
       " 0.008682204762049683,\n",
       " 0.003932298786002749,\n",
       " 0.019142378896851303,\n",
       " 0.01772779111833408,\n",
       " -0.008078732854968686,\n",
       " 0.012964906696022984,\n",
       " -0.02102417211442608,\n",
       " 0.010343374172021151,\n",
       " 0.011933165154338224,\n",
       " -0.01106364697320523,\n",
       " 0.01414589454897927,\n",
       " -0.00013180664051938538,\n",
       " 0.004899151355995847,\n",
       " 0.016196400583068548,\n",
       " 0.02399610825205977,\n",
       " 0.033820365993934565,\n",
       " 0.01331530937833223,\n",
       " -0.008351268584983414,\n",
       " -0.0016490024949486282,\n",
       " -0.0036824747548736695,\n",
       " 0.008669226781446828,\n",
       " 0.004665549567789683,\n",
       " -0.008468069479086496,\n",
       " 0.0025712434312424024,\n",
       " 0.001348077723403471,\n",
       " -0.025267941037913428,\n",
       " 0.026228304151943792,\n",
       " -0.010888444700727995,\n",
       " 0.002665333092121141,\n",
       " 0.027565025909489112,\n",
       " 0.029200240289577482,\n",
       " -0.026916132467282042,\n",
       " 0.006891256477372278,\n",
       " 0.01972638523001194,\n",
       " 0.009798302711991695,\n",
       " 0.004156167321587425,\n",
       " 0.019181313769982482,\n",
       " 0.025241985076707718,\n",
       " 0.0063234742497797845,\n",
       " 0.011180447867308313,\n",
       " -0.0015808685624449461,\n",
       " 0.005960093586867684,\n",
       " 0.018493485454644232,\n",
       " -0.004811550685418536,\n",
       " -0.016832316975995378,\n",
       " 0.004798572704815681,\n",
       " 0.009123452377256301,\n",
       " 0.01828583962764378,\n",
       " 0.004415725070999298,\n",
       " 0.018415617571027103,\n",
       " 0.015158168654098442,\n",
       " -0.02380143947433956,\n",
       " 0.018597309299467072,\n",
       " 0.0008881739700419332,\n",
       " -0.005084086415433264,\n",
       " 0.002175417816823165,\n",
       " 0.008234467690880333,\n",
       " 0.0009782080701899432,\n",
       " -0.005298221232735146,\n",
       " -0.002597199159617459,\n",
       " 0.026786352661253492,\n",
       " -0.01681933806406991,\n",
       " 0.03171794990007909,\n",
       " 0.013055751628920356,\n",
       " -0.0008751961058544048,\n",
       " 0.0016084465383953597,\n",
       " 0.0005284432186552276,\n",
       " -0.010122750364417843,\n",
       " -0.020842482248631337,\n",
       " -0.03480668506917064,\n",
       " 0.015599417200627672,\n",
       " 0.010505597532572918,\n",
       " -0.004704483043936942,\n",
       " -0.023554860636853154,\n",
       " -0.03916725674940629,\n",
       " 0.008935273055498823,\n",
       " 0.009052074880924518,\n",
       " 0.006119072685099391,\n",
       " -0.004779105733911398,\n",
       " 0.022815120399103484,\n",
       " 0.030316337308196883,\n",
       " -0.02246471771679424,\n",
       " 0.0020699725393322544,\n",
       " 0.0020245500728835685,\n",
       " 0.03929703469278962,\n",
       " -0.0077218411823580125,\n",
       " 0.0012004543581992618,\n",
       " 0.007780241629409553,\n",
       " 0.000997674924678899,\n",
       " 0.004178879020473074,\n",
       " 0.0054864005544926235,\n",
       " -0.00530795495101794,\n",
       " -0.005973071567470539,\n",
       " 0.01750716637940816,\n",
       " -0.008299357593894606,\n",
       " -0.02115395192045463,\n",
       " -0.007397393995593171,\n",
       " 0.016365111536937826,\n",
       " -0.004175634292491707,\n",
       " 0.03275618089772658,\n",
       " -0.009493322496131135,\n",
       " 0.015236036537715571,\n",
       " 0.0005134375741023347,\n",
       " 0.0076893966965121815,\n",
       " -0.009259720707924971,\n",
       " -0.002154328714758852,\n",
       " 0.020076787912321183,\n",
       " -0.010551019999021605,\n",
       " -0.02547558686491388,\n",
       " -0.008584870373189578,\n",
       " -0.0183377515500552,\n",
       " -0.0015338237320055767,\n",
       " 0.05403991262420976,\n",
       " 0.022049426062793333,\n",
       " -0.00613205020004094,\n",
       " 0.0018055481636096368,\n",
       " 0.010875467651447753,\n",
       " 0.019311091713365806,\n",
       " -0.00021352675094752304,\n",
       " -0.014223761501273786,\n",
       " -0.013276375436523664,\n",
       " -0.014392474317788288,\n",
       " 0.010213595297315215,\n",
       " -0.01742929849579103,\n",
       " -0.013587845108346958,\n",
       " 0.003721408463851581,\n",
       " 0.004526037440462259,\n",
       " 0.0016838805267804845,\n",
       " 0.020232521816910216,\n",
       " -0.006806900534776334,\n",
       " 0.012588548052508029,\n",
       " -0.002902179375478019,\n",
       " -0.0063559187356256154,\n",
       " 0.0028843347685644197,\n",
       " 0.011589250996669099,\n",
       " 0.025813012497942885,\n",
       " 0.015365815412421508,\n",
       " 0.01201103210663274,\n",
       " 0.022802143349823244,\n",
       " 0.018921756020570606,\n",
       " 0.010213595297315215,\n",
       " -0.026020658324943338,\n",
       " -0.008526469926138036,\n",
       " -0.002355486017119185,\n",
       " 0.013613801069552667,\n",
       " 0.006352674473305555,\n",
       " -0.001146920537458465,\n",
       " 0.027720761676723372,\n",
       " -0.010966312584345125,\n",
       " 0.010518575513175773,\n",
       " 0.022503652589925417,\n",
       " -0.012218677933633194,\n",
       " 0.006800411544474906,\n",
       " 0.016949117870098458,\n",
       " 0.005353377417466626,\n",
       " -0.017014006841790122,\n",
       " 0.018091170849923566,\n",
       " -0.019388959596982936,\n",
       " -0.01964851734639481,\n",
       " 0.032340889243725676,\n",
       " -0.009791814187351573,\n",
       " -0.009188342280270574,\n",
       " 0.028499434924958992,\n",
       " 0.0009830746965006872,\n",
       " -0.016105553787525952,\n",
       " -0.010505597532572918,\n",
       " -0.0017568810855949106,\n",
       " 0.006024983024220653,\n",
       " -0.020154653933293087,\n",
       " -0.01131671526665437,\n",
       " -0.009136430357859155,\n",
       " 0.007663440735306472,\n",
       " -0.010862489670844898,\n",
       " -0.020141676884012846,\n",
       " 0.00772833017265944,\n",
       " -0.006498675590934407,\n",
       " -0.028369655118930442,\n",
       " -0.03192559758972477,\n",
       " -0.027616937831900532,\n",
       " -0.011809874804272407,\n",
       " -0.0156772850842448,\n",
       " 0.003688963745175097,\n",
       " -0.016144488660657128,\n",
       " -0.0013383443543666565,\n",
       " -0.011946143134941078,\n",
       " -0.005603201448595705,\n",
       " 0.0018444818725875485,\n",
       " 0.01737738657337961,\n",
       " 0.004860217879848589,\n",
       " -0.013756557924861459,\n",
       " 0.024437355867266388,\n",
       " 0.007066458284188207,\n",
       " -0.01226410040008188,\n",
       " -0.030549940959048272,\n",
       " 0.0021283729863837953,\n",
       " -0.01835072859933544,\n",
       " 0.013107663551331776,\n",
       " 0.00986968113964609,\n",
       " -0.009597145409631361,\n",
       " -0.0048861733753929925,\n",
       " -0.008734116684461102,\n",
       " 0.000829773464782729,\n",
       " 0.02560536667094243,\n",
       " 0.011005245594831077,\n",
       " 0.010940356623139415,\n",
       " -0.008623804314998143,\n",
       " 0.0027350891557848538,\n",
       " -0.012893528268368587,\n",
       " 0.019181313769982482,\n",
       " 0.0002557048677646535,\n",
       " -0.011115557964294039,\n",
       " -0.015002434749509408,\n",
       " 0.003945276766605604,\n",
       " 0.002821067695202135,\n",
       " -0.0028843347685644197,\n",
       " -0.010946845147779537,\n",
       " 0.015884930911245255,\n",
       " 0.0017731034449331527,\n",
       " 0.011660629424323495,\n",
       " 0.009110475327976058,\n",
       " -0.01845455244415828,\n",
       " -0.011465960646603284,\n",
       " 0.0335088981847565,\n",
       " -0.010518575513175773,\n",
       " 0.010810577748433478,\n",
       " -0.0005235765341368203,\n",
       " -0.0014462229450129388,\n",
       " 0.017169740746379156,\n",
       " 0.003883631824403349,\n",
       " 0.02638403991917805,\n",
       " 0.00048748178751961474,\n",
       " -0.03519602262461106,\n",
       " 0.008305846118534728,\n",
       " -0.03955659057955627,\n",
       " 0.03010869148119643,\n",
       " -0.0042080792439988446,\n",
       " 0.007676418715909327,\n",
       " 0.003310982737669458,\n",
       " 0.01443140732827424,\n",
       " -0.010745688776741816,\n",
       " -0.003491050937965478,\n",
       " 0.0017439032214073822,\n",
       " -0.00721570366413712,\n",
       " 0.02110203999804321,\n",
       " 0.008967718472667266,\n",
       " -0.01570324104545051,\n",
       " -0.02580003358601742,\n",
       " -0.014158871598259511,\n",
       " -0.027123778294282495,\n",
       " 0.011699562434809447,\n",
       " -0.00018027092303527623,\n",
       " -0.027513115849722918,\n",
       " -0.021011195065145837,\n",
       " -0.011349159752500202,\n",
       " 0.0028973127491672746,\n",
       " -0.014171849578862366,\n",
       " -0.02346401570395578,\n",
       " -0.0436056907253234,\n",
       " -0.01198507614542703,\n",
       " 0.00981776921723467,\n",
       " -0.01023306180255819,\n",
       " 0.010382307182507104,\n",
       " -0.005262532018907948,\n",
       " 0.0025469098340273762,\n",
       " -0.024177798117854515,\n",
       " -0.04046504363382043,\n",
       " -0.007981399397431192,\n",
       " -0.026890176506076332,\n",
       " -0.016339157438377338,\n",
       " 0.0014008003621489263,\n",
       " 0.034028013683580244,\n",
       " 0.021699023380484087,\n",
       " 0.018506462503924476,\n",
       " 0.0014665009814972363,\n",
       " 0.0029865357837352696,\n",
       " 0.0008261234368420078,\n",
       " 0.01770183515712837,\n",
       " 0.01637809044886329,\n",
       " -0.007916509494416918,\n",
       " 0.010758665826022059,\n",
       " -0.017416321446510785,\n",
       " 0.02258151861089732,\n",
       " 0.03286000474254942,\n",
       " 0.020258477778115926,\n",
       " 0.0037311417164730696,\n",
       " 0.009603634865594094,\n",
       " 0.022010491189662154,\n",
       " 0.01831179558884949,\n",
       " 0.002460931294610095,\n",
       " -0.01253663613009661,\n",
       " -0.00948034451552828,\n",
       " -0.03636403156564188,\n",
       " -0.006145028180643795,\n",
       " -0.010985779089588102,\n",
       " -0.011491916607808994,\n",
       " 0.008189045224431646,\n",
       " 0.008299357593894606,\n",
       " -0.009551722943182676,\n",
       " 0.032808092820138,\n",
       " 0.019479804529880306,\n",
       " 0.03724652679605511,\n",
       " 0.009467366534925425,\n",
       " 0.02177688940145599,\n",
       " 0.004577948897212372,\n",
       " 0.028629212868342316,\n",
       " 0.016053643727759755,\n",
       " 0.016053643727759755,\n",
       " 0.016196400583068548,\n",
       " -0.004182123282793135,\n",
       " -0.00800735442731429,\n",
       " -0.009564700923785531,\n",
       " 0.0203493227110133,\n",
       " -0.0037149194735501536,\n",
       " 0.007624507259159213,\n",
       " -0.020284433739321636,\n",
       " 0.009408966087873885,\n",
       " -0.011783918843066697,\n",
       " 0.01574217405593646,\n",
       " -0.0065311205424415444,\n",
       " -0.019505760491086016,\n",
       " -0.015158168654098442,\n",
       " -0.006232628851221106,\n",
       " -0.016858271074555863,\n",
       " -0.014574164183583031,\n",
       " -0.0017844590615453241,\n",
       " -0.02198453709110167,\n",
       " 0.010778133262587647,\n",
       " -0.011050668992602377,\n",
       " -0.010719732815536107,\n",
       " 0.017662900283997193,\n",
       " -0.01881793217574777,\n",
       " -0.026176392229532372,\n",
       " 0.0015038123264844647,\n",
       " -0.013256908931280688,\n",
       " 0.027824583658900986,\n",
       " 0.00034634729620150646,\n",
       " 0.014885633855406324,\n",
       " 0.013445088253038166,\n",
       " -0.025813012497942885,\n",
       " -0.020712704305248013,\n",
       " -0.005732980323301642,\n",
       " 0.007351971529144484,\n",
       " -0.0037116749783994403,\n",
       " 0.018830911087673236,\n",
       " -0.0029330019629944725,\n",
       " -0.005784891780051755,\n",
       " -0.021608178447586713,\n",
       " 0.008260423652086043,\n",
       " -0.0024203754544721533,\n",
       " 0.005035419221003212,\n",
       " -0.01576813001714217,\n",
       " 0.013717623983052894,\n",
       " 0.01845455244415828,\n",
       " -0.005294976970415085,\n",
       " -0.020699725393322543,\n",
       " -0.00844860297384352,\n",
       " -0.023892286269882157,\n",
       " 0.00831233464317485,\n",
       " 0.007280593101490088,\n",
       " 0.004454659012807863,\n",
       " -0.009162386319064865,\n",
       " -0.009551722943182676,\n",
       " -0.0038025201441274654,\n",
       " 0.026371061007252585,\n",
       " -0.026838264583664912,\n",
       " 0.017130807735893202,\n",
       " 0.02129670877576342,\n",
       " -0.01592386392173121,\n",
       " -0.011414049655514477,\n",
       " 0.007864597572005498,\n",
       " -0.015352837431818653,\n",
       " 0.02555345474853101,\n",
       " 0.0020115720922807136,\n",
       " 0.01755907830181958,\n",
       " -0.022347916822691157,\n",
       " 0.023619749608544814,\n",
       " 0.01579408597834788,\n",
       " 0.0025258207319630633,\n",
       " -0.020946306093454176,\n",
       " -0.00017804034717107636,\n",
       " -0.001146920537458465,\n",
       " 0.02977126771081265,\n",
       " -0.007566106812107672,\n",
       " 0.004483859236333633,\n",
       " 0.0006651165582449361,\n",
       " 0.011057157517242497,\n",
       " 0.010421241124315668,\n",
       " -0.0018493484988982927,\n",
       " -0.013328287358935084,\n",
       " -0.022140270995690704,\n",
       " -0.02046612360511638,\n",
       " -0.002496620508437293,\n",
       " 0.0424117276857321,\n",
       " 0.012108366495492845,\n",
       " -0.019285135752160096,\n",
       " -0.013445088253038166,\n",
       " -0.021893690295559074,\n",
       " -0.019324070625291272,\n",
       " -0.03174390399863958,\n",
       " 0.006037960539162201,\n",
       " 0.0015411237878870194,\n",
       " 0.0018428596250121916,\n",
       " -0.018675175320438976,\n",
       " -0.022477696628719707,\n",
       " 0.0009392743612120316,\n",
       " 0.01373060196365575,\n",
       " 0.01587195199931979,\n",
       " -0.008494025440292206,\n",
       " -0.006858811991526447,\n",
       " 0.019337047674571516,\n",
       " -0.021335641786249374,\n",
       " 0.009597145409631361,\n",
       " -0.004850484161565794,\n",
       " -0.0011947764334778496,\n",
       " -0.043034663304088235,\n",
       " 0.019285135752160096,\n",
       " -0.009408966087873885,\n",
       " -0.015547505278216252,\n",
       " 0.009447900029682448,\n",
       " -0.008403180507394834,\n",
       " -0.0352998464694339,\n",
       " -0.0022873520846155024,\n",
       " 0.014444385308877095,\n",
       " 0.01758503426302529,\n",
       " 0.02193262516869025,\n",
       " -0.008429135537277931,\n",
       " 0.02326934692623557,\n",
       " 0.008442113517880786,\n",
       " -0.010129238889057963,\n",
       " -0.005658357633327185,\n",
       " -0.025203052066221768,\n",
       " 0.006446764134184294,\n",
       " -0.023476992753236024,\n",
       " -0.0028145787049007076,\n",
       " -0.010888444700727995,\n",
       " 0.0016790137840544139,\n",
       " 0.027175690216693915,\n",
       " -0.01404207070415643,\n",
       " 0.019869140222675503,\n",
       " -0.003831720367653236,\n",
       " -0.02032336674980759,\n",
       " -0.019142378896851303,\n",
       " -0.005625913147481354,\n",
       " 0.02640999401773854,\n",
       " -0.014703943058288968,\n",
       " 0.02416482106857427,\n",
       " 0.0014689342946526084,\n",
       " -0.010635376407278855,\n",
       " -0.01659871518778921,\n",
       " 0.008935273055498823,\n",
       " 0.0030222247647318143,\n",
       " -0.0069107234482765605,\n",
       " 0.016326178526451872,\n",
       " 0.006995079856533811,\n",
       " -0.010453685610161498,\n",
       " 0.004337858118704781,\n",
       " -0.0054085331365368,\n",
       " -0.012614504013713739,\n",
       " 0.0034066947625388806,\n",
       " -0.02774671763792908,\n",
       " -0.01017466135550665,\n",
       " 0.006742011097423365,\n",
       " -0.007098902770034038,\n",
       " 0.01604066481583429,\n",
       " 0.022503652589925417,\n",
       " -0.03023847128722498,\n",
       " -0.01755907830181958,\n",
       " 0.00211215074346088,\n",
       " -0.026760398562693008,\n",
       " -0.00787108702796823,\n",
       " -0.0001351525043156852,\n",
       " 0.013393176330626746,\n",
       " 0.027954363464929535,\n",
       " 0.009240254202681994,\n",
       " -0.0021478399572880777,\n",
       " 0.014055048684759285,\n",
       " 0.003119558920761267,\n",
       " 0.014016115674273332,\n",
       " -0.005632401672121475,\n",
       " -0.01020710584135248,\n",
       " 0.005158709105407721,\n",
       " -0.004425458789282092,\n",
       " 0.017117828823967736,\n",
       " 0.0024885093869758354,\n",
       " -0.03579300414440671,\n",
       " -0.02543665385442793,\n",
       " 0.016936138958172992,\n",
       " -0.0017714811973577958,\n",
       " -0.016287245515965918,\n",
       " 0.020063809000395717,\n",
       " -0.005784891780051755,\n",
       " -0.00859135982915231,\n",
       " -0.015197102595907007,\n",
       " 0.006349430210985494,\n",
       " -0.008610826334395288,\n",
       " -0.0018315038919846937,\n",
       " 0.011855297270721094,\n",
       " -0.0077088632017551575,\n",
       " -3.067039266689553e-05,\n",
       " 0.01981723016290931,\n",
       " -0.025592387759016965,\n",
       " 0.0020391501846464535,\n",
       " -0.0065051645812358345,\n",
       " -0.0031260479110626943,\n",
       " -0.001990482990216401,\n",
       " 0.0006172606040178882,\n",
       " -0.01848050840536399,\n",
       " -0.004788839452194193,\n",
       " 0.015249014518318426,\n",
       " -0.024294599011957598,\n",
       " 0.016352134487657582,\n",
       " 0.004636349344263913,\n",
       " -0.02173795639097004,\n",
       " 0.039608502501967686,\n",
       " -0.010739199320779083,\n",
       " -0.00041346728031484305,\n",
       " -0.021673067419278377,\n",
       " 0.0038122536295796066,\n",
       " -0.010466663590764353,\n",
       " -0.011141513925499748,\n",
       " 0.022957877254412278,\n",
       " -0.001110420258051252,\n",
       " -0.011362137733103057,\n",
       " -0.019427892607468886,\n",
       " -0.007124858731239748,\n",
       " -0.029537665922606485,\n",
       " -0.002569621067251719,\n",
       " -0.03345698626234508,\n",
       " -0.005509111787716966,\n",
       " -0.014548208222377321,\n",
       " 0.02699400035089917,\n",
       " -0.006839345020622165,\n",
       " -0.0035462068898663053,\n",
       " -0.0021202618649223378,\n",
       " -0.010155194850263673,\n",
       " -0.014444385308877095,\n",
       " -0.007819175105556811,\n",
       " -0.008481047459689351,\n",
       " 0.018506462503924476,\n",
       " 0.012608014557751004,\n",
       " -0.004824528666021391,\n",
       " -0.004694749791315454,\n",
       " -0.004091277884234456,\n",
       " -0.02888877061775419,\n",
       " -0.005583734943352729,\n",
       " 0.01828583962764378,\n",
       " -0.001462445304351181,\n",
       " 0.0240739761356769,\n",
       " 0.2023511759929531,\n",
       " 3.7615585529207786e-05,\n",
       " -0.00301573600726104,\n",
       " 0.041814742440645994,\n",
       " 0.007001568846835239,\n",
       " 0.0032655602712207722,\n",
       " 0.01598875289342287,\n",
       " 0.02120586384286605,\n",
       " -0.020972262054659886,\n",
       " 0.019752339328572423,\n",
       " -0.019895096183881213,\n",
       " 0.013432110272435311,\n",
       " -0.021283729863837954,\n",
       " 0.0012077544140807045,\n",
       " 0.014976478788303698,\n",
       " -0.005771914265110207,\n",
       " -0.031224790362461053,\n",
       " -0.008117666796777251,\n",
       " -0.03519602262461106,\n",
       " -0.012828638365354313,\n",
       " -0.012134322456698555,\n",
       " -0.002681555335044057,\n",
       " -0.01754609938989411,\n",
       " -0.002027794335203629,\n",
       " 0.03620829952369807,\n",
       " 0.013821446896553121,\n",
       " 0.003028713755033242,\n",
       " 0.006806900534776334,\n",
       " 0.018065214888717856,\n",
       " 0.006904234457975133,\n",
       " -0.012166766942544387,\n",
       " -0.03465095302722683,\n",
       " 0.013899313848847638,\n",
       " 0.012711837471251231,\n",
       " -0.0010009193034142862,\n",
       " -0.007961931960865604,\n",
       " -0.007643973764402189,\n",
       " 0.0017406587262566685,\n",
       " 0.017247608629996285,\n",
       " -0.003020602633571784,\n",
       " -0.0019304602955895031,\n",
       " 0.012659926480162424,\n",
       " 0.01548261630652459,\n",
       " -0.015197102595907007,\n",
       " -0.01676742614165849,\n",
       " 0.007488239394151849,\n",
       " ...]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "embedder = OpenAIEmbeddings()\n",
    "\n",
    "vector = embedder.embed_query(\"hi\")\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1536"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6.4.2 VectorStore**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores.chroma import Chroma\n",
    "\n",
    "spliter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "    separator=\"\\n\\n\",\n",
    "    chunk_size=200,\n",
    "    chunk_overlap=50,\n",
    ")\n",
    "loader = UnstructuredFileLoader(\"./files/chapter_one.txt\") \n",
    "docs = loader.load_and_split(text_splitter=spliter)\n",
    "embeddings = OpenAIEmbeddings()\n",
    "vectorstore = Chroma.from_documents(documents=docs, embedding=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(page_content='they could plug in your wire whenever they wanted to. You\\n\\nhad to live—did live, from habit that became instinct—in\\n\\nthe assumption that every sound you made was overheard,\\n\\nand, except in darkness, every movement scrutinized.\\n\\nWinston kept his back turned to the telescreen. It was\\n\\nsafer, though, as he well knew, even a back can be revealing.\\n\\nA kilometre away the Ministry of Truth, his place of work,\\n\\ntowered vast and white above the grimy landscape. This,\\n\\nhe thought with a sort of vague distaste—this was London,\\n\\nchief city of Airstrip One, itself the third most populous\\n\\nof the provinces of Oceania. He tried to squeeze out some\\n\\nchildhood memory that should tell him whether London\\n\\nhad always been quite like this. Were there always these vistas of rotting nineteenth-century houses, their sides shored', metadata={'source': './files/chapter_one.txt'}), Document(page_content='Part 1, Chapter 1\\n\\nPart One\\n\\n1\\n\\nIt was a bright cold day in April, and the clocks were striking thirteen. Winston Smith, his chin nuzzled into his\\n\\nbreast in an effort to escape the vile wind, slipped quickly\\n\\nthrough the glass doors of Victory Mansions, though not\\n\\nquickly enough to prevent a swirl of gritty dust from entering along with him.\\n\\nThe hallway smelt of boiled cabbage and old rag mats. At\\n\\none end of it a coloured poster, too large for indoor display,\\n\\nhad been tacked to the wall. It depicted simply an enormous face, more than a metre wide: the face of a man of\\n\\nabout forty-five, with a heavy black moustache and ruggedly handsome features. Winston made for the stairs. It was\\n\\nno use trying the lift. Even at the best of times it was seldom working, and at present the electric current was cut', metadata={'source': './files/chapter_one.txt'}), Document(page_content='with jointed truncheons.\\n\\nWinston turned round abruptly. He had set his features\\n\\ninto the expression of quiet optimism which it was advisable to wear when facing the telescreen. He crossed the\\n\\nroom into the tiny kitchen. By leaving the Ministry at this\\n\\ntime of day he had sacrificed his lunch in the canteen, and\\n\\nhe was aware that there was no food in the kitchen except\\n\\na hunk of dark-coloured bread which had got to be saved\\n\\nfor tomorrow’s breakfast. He took down from the shelf a\\n\\nbottle of colourless liquid with a plain white label marked\\n\\nVICTORY GIN. It gave off a sickly, oily smell, as of Chinese\\n\\nrice-spirit. Winston poured out nearly a teacupful, nerved\\n\\nhimself for a shock, and gulped it down like a dose of medicine.\\n\\nInstantly his face turned scarlet and the water ran out', metadata={'source': './files/chapter_one.txt'}), Document(page_content='floor. With the next he was more successful. He went back\\n\\nto the living-room and sat down at a small table that stood\\n\\nto the left of the telescreen. From the table drawer he took\\n\\nout a penholder, a bottle of ink, and a thick, quarto-sized\\n\\nblank book with a red back and a marbled cover.\\n\\nFor some reason the telescreen in the living-room was in\\n\\nan unusual position. Instead of being placed, as was normal,\\n\\nin the end wall, where it could command the whole room,\\n\\nit was in the longer wall, opposite the window. To one side\\n\\nof it there was a shallow alcove in which Winston was now\\n\\nsitting, and which, when the flats were built, had probably\\n\\nbeen intended to hold bookshelves. By sitting in the alcove,\\n\\nand keeping well back, Winston was able to remain outside', metadata={'source': './files/chapter_one.txt'})]\n"
     ]
    }
   ],
   "source": [
    "result = vectorstore.similarity_search(\"where dose winston live\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6.4.3 Caching**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.storage.file_system import LocalFileStore\n",
    "from langchain.embeddings.cache import CacheBackedEmbeddings\n",
    "\n",
    "cache_dir = LocalFileStore(\"./.cache/\")\n",
    "cached_embeddings = CacheBackedEmbeddings.from_bytes_store(embeddings, cache_dir)\n",
    "vectorstore = Chroma.from_documents(documents=docs, embedding=cached_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.6 RetrievalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Winston lives in Victory Mansions.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains.retrieval_qa.base import RetrievalQA\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=vectorstore.as_retriever()  # 'retriver'를 'retriever'로 수정\n",
    ")\n",
    "\n",
    "chain.run(\"where does Winston live?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
