## 4. MODEL IO

### 4.1 FewShotPromptTemplate

ğŸ“Œ **PromptTemplateì˜ ë°©ë²• 2ê°€ì§€**

```python
# 1
t = PromptTemplate.from_template("What is the capital of {country}?",)

# 2
t = PromptTemplate(
    template="What is the capital of {country}?",
    input_variables=["country"],
)

print(t.format(country="France"))
```

```
PromptTemplate(input_variables=['country'], template='What is the capital of {country}?')
```

ğŸ‘€ **FewShot**

> ì–´ë–»ê²Œ ëŒ€ë‹µí•´ì•¼í•˜ëŠ”ì§€ ëª¨ë¸ì—ê²Œ ì˜ˆì œë¥¼ ì¤Œ

ğŸ“ **FewShotPromptTemplate**

> Prompt template that contains few shot examples.

- ì˜ˆì‹œì™€ ì‚¬ìš©ì ì§ˆë¬¸ì´ í¬í•¨ë˜ëŠ” í…œí”Œë¦¿
- _parameters_
  - example_prompt: PromptTemplate
  - example: ì˜ˆì‹œ ë¬¸ë‹µ
  - suffix: ì˜ˆì‹œ ë¬¸ë‹µ ë’¤ì— ë¶™ì¼ ì‚¬ìš©ìì˜ ì§ˆë¬¸
  - input_variables: ì§ˆë¬¸ì— ë“¤ì–´ê°ˆ í‚¤ì›Œë“œ (ìœ íš¨ì„± ê²€ì¦ì„ ìœ„í•´ ì‚¬ìš©)

### 4.2 FewShotChatMessagePromptTemplate

ğŸ“ **FewShotPromptTemplate**

> Chat prompt template that supports few-shot examples.

- step1. ì˜ˆì‹œ ë¬¸ë‹µì„ í†µí•´ FewShotChatMessagePromptTemplate í˜•ì‹ì˜ í”„ë¡¬í”„íŠ¸ë¥¼ ë§Œë“¤ê³ 
- step2. ChatPromptTemplateì¸ ë©”ì„¸ì§€ í…œí”Œë¦¿ì— ë“¤ì–´ê°

ğŸŒˆ **Example**

_example_prompt_

```

examples=[
    {'country': 'France', 'answer': '\n        Here is what I know:\n        Capital: Paris\n        Language: French\n        Food: Wine and Cheese\n        Currency: Euro\n        '},
    {'country': 'Italy', 'answer': '\n        I know this:\n        Capital: Rome\n        Language: Italian\n        Food: Pizza and Pasta\n        Currency: Euro\n        '},
    {'country': 'Greece', 'answer': '\n        I know this:\n        Capital: Athens\n        Language: Greek\n        Food: Souvlaki and Feta Cheese\n        Currency: Euro\n        '}
    ]
example_prompt=ChatPromptTemplate(
    input_variables=['answer', 'country'],
    messages=[
        HumanMessagePromptTemplate(
            prompt=PromptTemplate(
                input_variables=['country'],
                template='What do you know about {country}?'
                )
            ),
        AIMessagePromptTemplate(
            prompt=PromptTemplate(
                input_variables=['answer'],
                template='{answer}'
            )
        )
    ]
)
```

_final_prompt_

```
input_variables=['country']
messages=[
    SystemMessagePromptTemplate(
        prompt=PromptTemplate(
            input_variables=[],
            template='You are a geography expert, you give short answers.'
        )
    ),
    FewShotChatMessagePromptTemplate(
        examples=[
            {'country': 'France', 'answer': '\n        Here is what I know:\n        Capital: Paris\n        Language: French\n        Food: Wine and Cheese\n        Currency: Euro\n        '},
            {'country': 'Italy', 'answer': '\n        I know this:\n        Capital: Rome\n        Language: Italian\n        Food: Pizza and Pasta\n        Currency: Euro\n        '},
            {'country': 'Greece', 'answer': '\n        I know this:\n        Capital: Athens\n        Language: Greek\n        Food: Souvlaki and Feta Cheese\n        Currency: Euro\n        '}
        ],
        example_prompt=ChatPromptTemplate(
            input_variables=['answer', 'country'],
            messages=[
                HumanMessagePromptTemplate(
                    prompt=PromptTemplate(
                        input_variables=['country'],
                        template='What do you know about {country}?'
                    )
                ),
                AIMessagePromptTemplate(
                    prompt=PromptTemplate(
                        input_variables=['answer'],
                        template='{answer}'
                    )
                )
            ]
        )
    ),
    HumanMessagePromptTemplate(
        prompt=PromptTemplate(
            input_variables=['country'],
            template='What do you know about {country}?'
        )
    )
]
```

### 4.3 LengthBasedExampleSelector

ğŸ“ **LengthBasedExampleSelector**

> Select examples based on length.

- ì˜ˆì œì˜ ì–‘ì´ ì–¼ë§ˆë‚˜ ë˜ëŠ”ì§€ í™•ì¸ ê°€ëŠ¥
- ì„¤ì •í•´ ë†“ì€ setting ê°’ì— ë”°ë¼ promptì— ì•Œë§ì€ ì˜ˆì œë¥¼ ê³¨ë¼ì¤Œ
  - í™œìš©: ë¡œê·¸ì¸ ì—¬ë¶€, ìœ ì €ê°€ ì‚¬ìš©í•˜ëŠ” ì–¸ì–´ ë“±ì— ë”°ë¼ì„œ ì œí•œì„ ë‹¤ë¥´ê²Œ ë‘˜ ìˆ˜ ìˆìŒ
- FewShotChatMessagePromptTemplateì´ ë¦¬ìŠ¤íŠ¸ì— ìˆëŠ” ëª¨ë“  ì˜ˆì œë“¤ì„ ê°€ì§€ê³  í˜•ì‹í™” í•´ì£¼ê¸° ì´ì „ì— ì ìš©
- _parameters_
  - max_lenght: ì„ íƒëœ ì˜ˆì œë“¤ì˜ ìµœëŒ€ ê¸¸ì´
  - examples
  - example_prompt

ğŸ“ **BaseExampleSelector**

> Interface for selecting examples to include in prompts.

- _abstract_
  - add_example
  - select_examples

### 4.4 Serialization and Composition

ğŸ“ **PipelinePromptTemplate**

> A prompt template for composing multiple prompt templates together.

### 4.5 Caching

ğŸ“ **Cache in LLM**

ğŸ‘€ **set_llm_cache**

> Set a new LLM cache, overwriting the previous value, if any.

ğŸ‘€ **InMemoryCache**

> Cache that stores things in memory.

ğŸ‘€ **SQLiteCache**

> Cache that uses SQLite as a backend.

ğŸŒˆ **example**

```python
set_llm_cache(InMemoryCache())
set_llm_cache(SQLiteCache('cache.db'))
```

- ëª¨ë“  responseê°€ ë©”ëª¨ë¦¬ì— ì €ì¥ë¨ (ë…¸íŠ¸ë¶ ì¬ì‹œì‘ê¹Œì§€, ì»¤ë„ ì£½ìœ¼ë©´ ë‚ ë¼ê°)
- ì§ˆë¬¸ì´ ì¡°ê¸ˆì´ë¼ë„ ë‹¬ë¼ì§€ë©´ ë‹¤ì‹œ ì €ì¥ë¨
