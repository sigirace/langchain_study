## Memory

📌 **모든 memory의 공통 api**

- save_context: Save context from this conversation to buffer.
- load_memory_variables: Return history buffer.

### 5.0 ConversationBufferMemory

- openai api는 memory를 지원하지 않음 ☞ 현재는 어떤지 모름
- langchain은 메모리를 통해 실제 대화의 느낌을 지원

📍 **ConversationBufferMemory**

> Buffer for storing conversation memory.

- 이전 대화 내용 전체를 기억함
- 내용이 길어질 수록 메모리 낭비가 커져서 비효율적

### 5.1 ConversationBufferWindowMemory

📍 **ConversationBufferWindowMemory**

> Buffer for storing conversation memory inside a limited size window.

- _parameters_
  - k: 버퍼 윈도우의 사이즈, 몇개의 메세지를 저장할지를 뜻함

### 5.2 ConversationSummaryMemory

📍 **ConversationSummaryMemory**

> Conversation summarizer to chat memory.

- llm을 사용하여 대화를 요약함

📌 **ConversationSummaryMemory와 메모리 관계**

- 대화가 없는 초반 차지하는 메모리가 상대적으로 큼
- 대화가 길어질수록 차지하는 메모리는 상대적으로 작음

### 5.3 ConversationSummaryBufferMemory

📍 **ConversationSummaryBufferMemory**

> Buffer with summarizer for storing conversation memory.

- ConversationBufferMemory, ConversationSummaryMemory를 결합
- 메모리에 보내온 메세지의 수를 저장
- limit에 다른 순간에 오래된 메세지를 요약함
- 즉, 가장 최근의 상호 작용을 계속 추적하며 과거는 요약으로 가지고 있음
- _parameter_
  - max_token_limit: 요약되기 전 가능한 메시지 토큰 수의 최대값

### 5.4 ConversationKGMemory

> Knowledge graph conversation memory.

- 질문에 대해 엔티티를 추출해서 Knowledge Graph를 생성함
- 외부 지식 그래프와 통합하여 대화에서 지식 트리플에 대한 정보를 저장하고 검색

❤️‍🔥 **Memory Types**

- [(공식문서) 메모리 타입](https://python.langchain.com/v0.1/docs/modules/memory/types/)

### 5.5 Memory on LLMChain

📍 **LLM Chain**

- LangChain 라이브러리에서 제공하는 고수준의 추상화로 LLM 기반의 체인을 생성하고 관리하는 데 사용됨
- LLMChain은 주로 프롬프트 템플릿과 언어 모델을 결합하여 일관된 방식으로 입력을 처리하고, 모델의 출력을 얻기 위해 사용됨
- _parameters_
  - llm: Large Language Model
  - memory: buffer
  - prompt: prompt
  - verbose: logs

👀 **off-the-shelf**

- 일반적인 목적을 가진 chain (llm chain)
- 반대 개념은 custom chain

💡 **해석**

- 앞서 chain을 만들때, interface 규칙에 맞춰 커스텀으로 구성했음
- LLMchain을 쓰면 이 내용은 고민하지 않고 Args만 전달하면 됨

📌 **LLMChain에서 프롬프트에 메모리를 적용하는 방법**

- step1. Memory 생성
  - 모든 Memory는 memory_key를 가지고 있음
- step2. String 기반의 template를 만듦
  - template안에는 memory_key의 변수명으로 과거 내용을 담을 수 있는 placeholder 존재
- step3. LLMChain 인스턴스 생성
  - LLMChain 내에서 memory와 template의 공통된 memory_key를 연결함

### 5.6 Chat Based Memory

- Memory를 단순 text가 아닌 Chat Message 형태로 저장
- _parameters_
  - return_messages=True

📍 **MessagesPlaceholder**

> Prompt template that assumes variable is already list of messages.

- 과거 대화(messages)로부터 ChatPromptTemplate을 만들어야함
- 그러나 과거 대화(messages)가 몇개인지 알 수 없음
- 얼마만큼의 공간을 할당해야할지 모를때 `MessagePlaceholder`를 사용
- _parameters_
  - variable_name: message_key
