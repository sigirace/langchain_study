## Memory

ğŸ“Œ **ëª¨ë“  memoryì˜ ê³µí†µ api**

- save_context: Save context from this conversation to buffer.
- load_memory_variables: Return history buffer.

### 5.0 ConversationBufferMemory

- openai apiëŠ” memoryë¥¼ ì§€ì›í•˜ì§€ ì•ŠìŒ â˜ í˜„ì¬ëŠ” ì–´ë–¤ì§€ ëª¨ë¦„
- langchainì€ ë©”ëª¨ë¦¬ë¥¼ í†µí•´ ì‹¤ì œ ëŒ€í™”ì˜ ëŠë‚Œì„ ì§€ì›

ğŸ“ **ConversationBufferMemory**

> Buffer for storing conversation memory.

- ì´ì „ ëŒ€í™” ë‚´ìš© ì „ì²´ë¥¼ ê¸°ì–µí•¨
- ë‚´ìš©ì´ ê¸¸ì–´ì§ˆ ìˆ˜ë¡ ë©”ëª¨ë¦¬ ë‚­ë¹„ê°€ ì»¤ì ¸ì„œ ë¹„íš¨ìœ¨ì 

### 5.1 ConversationBufferWindowMemory

ğŸ“ **ConversationBufferWindowMemory**

> Buffer for storing conversation memory inside a limited size window.

- _parameters_
  - k: ë²„í¼ ìœˆë„ìš°ì˜ ì‚¬ì´ì¦ˆ, ëª‡ê°œì˜ ë©”ì„¸ì§€ë¥¼ ì €ì¥í• ì§€ë¥¼ ëœ»í•¨

### 5.2 ConversationSummaryMemory

ğŸ“ **ConversationSummaryMemory**

> Conversation summarizer to chat memory.

- llmì„ ì‚¬ìš©í•˜ì—¬ ëŒ€í™”ë¥¼ ìš”ì•½í•¨

ğŸ“Œ **ConversationSummaryMemoryì™€ ë©”ëª¨ë¦¬ ê´€ê³„**

- ëŒ€í™”ê°€ ì—†ëŠ” ì´ˆë°˜ ì°¨ì§€í•˜ëŠ” ë©”ëª¨ë¦¬ê°€ ìƒëŒ€ì ìœ¼ë¡œ í¼
- ëŒ€í™”ê°€ ê¸¸ì–´ì§ˆìˆ˜ë¡ ì°¨ì§€í•˜ëŠ” ë©”ëª¨ë¦¬ëŠ” ìƒëŒ€ì ìœ¼ë¡œ ì‘ìŒ

### 5.3 ConversationSummaryBufferMemory

ğŸ“ **ConversationSummaryBufferMemory**

> Buffer with summarizer for storing conversation memory.

- ConversationBufferMemory, ConversationSummaryMemoryë¥¼ ê²°í•©
- ë©”ëª¨ë¦¬ì— ë³´ë‚´ì˜¨ ë©”ì„¸ì§€ì˜ ìˆ˜ë¥¼ ì €ì¥
- limitì— ë‹¤ë¥¸ ìˆœê°„ì— ì˜¤ë˜ëœ ë©”ì„¸ì§€ë¥¼ ìš”ì•½í•¨
- ì¦‰, ê°€ì¥ ìµœê·¼ì˜ ìƒí˜¸ ì‘ìš©ì„ ê³„ì† ì¶”ì í•˜ë©° ê³¼ê±°ëŠ” ìš”ì•½ìœ¼ë¡œ ê°€ì§€ê³  ìˆìŒ
- _parameter_
  - max_token_limit: ìš”ì•½ë˜ê¸° ì „ ê°€ëŠ¥í•œ ë©”ì‹œì§€ í† í° ìˆ˜ì˜ ìµœëŒ€ê°’

### 5.4 ConversationKGMemory

> Knowledge graph conversation memory.

- ì§ˆë¬¸ì— ëŒ€í•´ ì—”í‹°í‹°ë¥¼ ì¶”ì¶œí•´ì„œ Knowledge Graphë¥¼ ìƒì„±í•¨
- ì™¸ë¶€ ì§€ì‹ ê·¸ë˜í”„ì™€ í†µí•©í•˜ì—¬ ëŒ€í™”ì—ì„œ ì§€ì‹ íŠ¸ë¦¬í”Œì— ëŒ€í•œ ì •ë³´ë¥¼ ì €ì¥í•˜ê³  ê²€ìƒ‰

â¤ï¸â€ğŸ”¥ **Memory Types**

ğŸ“œ [ê³µì‹ë¬¸ì„œ-ë©”ëª¨ë¦¬ íƒ€ì…](https://python.langchain.com/v0.1/docs/modules/memory/types/)

### 5.5 Memory on LLMChain

ğŸ“ **LLM Chain**

- LangChain ë¼ì´ë¸ŒëŸ¬ë¦¬ì—ì„œ ì œê³µí•˜ëŠ” ê³ ìˆ˜ì¤€ì˜ ì¶”ìƒí™”ë¡œ LLM ê¸°ë°˜ì˜ ì²´ì¸ì„ ìƒì„±í•˜ê³  ê´€ë¦¬í•˜ëŠ” ë° ì‚¬ìš©ë¨
- LLMChainì€ ì£¼ë¡œ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ê³¼ ì–¸ì–´ ëª¨ë¸ì„ ê²°í•©í•˜ì—¬ ì¼ê´€ëœ ë°©ì‹ìœ¼ë¡œ ì…ë ¥ì„ ì²˜ë¦¬í•˜ê³ , ëª¨ë¸ì˜ ì¶œë ¥ì„ ì–»ê¸° ìœ„í•´ ì‚¬ìš©ë¨
- _parameters_
  - llm: Large Language Model
  - memory: buffer
  - prompt: prompt
  - verbose: logs

ğŸ‘€ **off-the-shelf**

- ì¼ë°˜ì ì¸ ëª©ì ì„ ê°€ì§„ chain (llm chain)
- ë°˜ëŒ€ ê°œë…ì€ custom chain

ğŸ’¡ **í•´ì„**

- ì•ì„œ chainì„ ë§Œë“¤ë•Œ, interface ê·œì¹™ì— ë§ì¶° ì»¤ìŠ¤í…€ìœ¼ë¡œ êµ¬ì„±í–ˆìŒ
- LLMchainì„ ì“°ë©´ ì´ ë‚´ìš©ì€ ê³ ë¯¼í•˜ì§€ ì•Šê³  Argsë§Œ ì „ë‹¬í•˜ë©´ ë¨

ğŸ“Œ **LLMChainì—ì„œ í”„ë¡¬í”„íŠ¸ì— ë©”ëª¨ë¦¬ë¥¼ ì ìš©í•˜ëŠ” ë°©ë²•**

- step1. Memory ìƒì„±
  - ëª¨ë“  MemoryëŠ” memory_keyë¥¼ ê°€ì§€ê³  ìˆìŒ
- step2. String ê¸°ë°˜ì˜ templateë¥¼ ë§Œë“¦
  - templateì•ˆì—ëŠ” memory_keyì˜ ë³€ìˆ˜ëª…ìœ¼ë¡œ ê³¼ê±° ë‚´ìš©ì„ ë‹´ì„ ìˆ˜ ìˆëŠ” placeholder ì¡´ì¬
- step3. LLMChain ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
  - LLMChain ë‚´ì—ì„œ memoryì™€ templateì˜ ê³µí†µëœ memory_keyë¥¼ ì—°ê²°í•¨

### 5.6 Chat Based Memory

- Memoryë¥¼ ë‹¨ìˆœ textê°€ ì•„ë‹Œ Chat Message í˜•íƒœë¡œ ì €ì¥
- _parameters_
  - return_messages=True

ğŸ“ **MessagesPlaceholder**

> Prompt template that assumes variable is already list of messages.

- ê³¼ê±° ëŒ€í™”(messages)ë¡œë¶€í„° ChatPromptTemplateì„ ë§Œë“¤ì–´ì•¼í•¨
- ê·¸ëŸ¬ë‚˜ ê³¼ê±° ëŒ€í™”(messages)ê°€ ëª‡ê°œì¸ì§€ ì•Œ ìˆ˜ ì—†ìŒ
- ì–¼ë§ˆë§Œí¼ì˜ ê³µê°„ì„ í• ë‹¹í•´ì•¼í• ì§€ ëª¨ë¥¼ë•Œ `MessagePlaceholder`ë¥¼ ì‚¬ìš©
- _parameters_
  - variable_name: message_key

### 5.7 LCEL Based Memory

â›”ï¸ **Error**

```python
llm = ChatOpenAI(temperature=0.1)

memory = ConversationSummaryBufferMemory(
    llm=llm,
    max_token_limit=50,
    memory_key="chat_history",
    return_messages=True,
)

prompt = ChatPromptTemplate.from_messages([
    ("system", "You are a chatbot that helps people with their daily life."),
    MessagesPlaceholder(variable_name="chat_history"),
    ("human", "{question}"),
])

chain = prompt | llm

chain.invoke({"question": "My name is Nico"})
```

- í•´ë‹¹ ë°©ì‹ìœ¼ë¡œ ìˆ˜í–‰í•œë‹¤ë©´ Promptì— ë“¤ì–´ê°€ëŠ” chat_historyì— ëŒ€í•œ ë‚´ìš©ì´ ì—†ìŒ
- LLMChainì—ì„œëŠ” frameworkê°€ ì´ë¥¼ ìë™í™”í•´ì£¼ì—ˆì§€ë§Œ, custom chainì„ ì‚¬ìš©í•  ê²½ìš° ì´ì— ëŒ€í•œ ì²˜ë¦¬ í•„ìš”

ğŸ’¥ **í•´ê²°ë°©ì•ˆ 1**

```python
chain.invoke({
    "chat_history": memory.load_memory_variables({})["chat_history"],
    "question": "My name is Nico"
})
```

- promptì˜ inputìœ¼ë¡œ chat_history key ì¶”ê°€

ğŸ’¥ **í•´ê²°ë°©ì•ˆ 2**

```python
from langchain.schema.runnable import RunnablePassthrough

def load_memory():
    return memory.load_memory_variables({})['chat_history']

chain = RunnablePassthrough.assign(chat_history=load_memory) | prompt | llm
```

- chain ì‹¤í–‰ì‹œ, ê°€ì¥ ë¨¼ì € load_memory í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•¨
- ë‹¨, memoryì— ëŒ€í•´ì„œ ë°ì´í„°ë¥¼ ìŒ“ëŠ” save_contextì— ëŒ€í•œ ìˆ˜ë™ êµ¬í˜„ í•„ìš”

```python
def invoke_chain(question):
    result = chain.invoke({"question": question})
    memory.save_context(
        {"input": question},
        {"output": result.content},
    )
```

ğŸ“ **RunnablePassthrough**

- ê°ì²´ëŠ” input_dataë¥¼ ë°›ì•„ì„œ ê·¸ëŒ€ë¡œ output_dataë¡œ ë°˜í™˜í•¨
- ì£¼ë¡œ ë°ì´í„° íŒŒì´í”„ë¼ì¸ì—ì„œ ì¤‘ê°„ ë‹¨ê³„ë¡œ ì‚¬ìš©ë˜ë©°, íŠ¹ì • ë‹¨ê³„ì—ì„œ ë°ì´í„°ë¥¼ ë³€ê²½í•˜ì§€ ì•Šê³  ê·¸ëŒ€ë¡œ ì „ë‹¬í•´ì•¼ í•  ë•Œ ìœ ìš©í•¨

ğŸŒˆ **example**

```python
def load_memory(input):
    return memory.load_memory_variables({})['chat_history']

chain = RunnablePassthrough.assign(chat_history=load_memory)

print(chain.invoke({"question": "My name is Nico"}))
```

```
{'question': 'My name is Nico', 'chat_history': []}
```

### 6.1 Data Loaders and Splitters

ğŸ“œ [ê³µì‹ë¬¸ì„œ-Retrival](https://python.langchain.com/v0.1/docs/modules/data_connection/)

ğŸ“ **UnstructureFileLoader**

- ë‹¤ì–‘í•œ íŒŒì¼ë“¤ì„ ê°€ì ¸ì˜¬ ìˆ˜ ìˆìŒ
- pdf, docx, excel, html ... even ppt!

ğŸ“Œ **loaderì˜ output**

```python
print(loader.load())
print(len(loader.load()))
```

```
[Document(page_content='~~~~~')]
1
```

- Document ê°ì²´ì˜ Listì¸ë° í•˜ë‚˜ë¡œ ëª¨ë‘ í¬í•¨ë˜ì–´ ìˆìŒ
  â˜ textë¥¼ ë‚˜ëˆ„ì–´ì¤˜ì•¼ í•  í•„ìš”ê°€ ìˆìŒ

ğŸ‘€ **chunk**

- chunk: ë¬¸ì„œê°€ ë‚˜ëˆ„ì–´ì§„ ë‹¨ìœ„
- chunk_size: ê¸€ì ìˆ˜
  - chunk_sizeë¥¼ ì¸¡ì •í•˜ëŠ” ê¸°ë³¸ì ì¸ ë°©ë²•ì€ pythonì˜ len function

ğŸ“ **RecursiveCharacterTextSplitter**

- ë¬¸ì¥ ëì´ë‚˜ ë¬¸ë‹¨ì˜ ëë¶€ë¶„ë§ˆë‹¤ ëŠì–´ì¤Œ
- ë¬¸ì¥ ì¤‘ê°„ì—ì„œ ì§¤ë ¤ ì˜ë¯¸ë¥¼ ìƒì–´ë²„ë¦¬ëŠ” ê²ƒì„ ë°©ì§€
- _parameters_
  - chunk_size: ë¬¸ë‹¨ì˜ ì‚¬ì´ì¦ˆ
  - chunk_overlap: ì• ì¡°ê°ì˜ ëì„ ì¡°ê¸ˆ ê°€ì ¸ì™€ ë¬¸ì¥ì„ ì—°ê²°ì‹œí‚´

ğŸ“ **CharacterTextSplitter**

- _parameters_
  - chunk_size, chunk_overlap
  - splitter: ë¬¸ë‹¨ì„ splite

â›”ï¸ **CharacterTextSplitterëŠ” ë‚´ ìƒê°ê³¼ ë‹¤ë¥´ê²Œ ë¶„í• í•œë‹¤!**

ğŸ“œ [Stackoverflow CharacterTextSplitter](https://stackoverflow.com/questions/76633836/what-does-langchain-charactertextsplitters-chunk-size-param-even-do)

- CharacterTextSplitterëŠ” êµ¬ë¶„ ê¸°í˜¸(ê¸°ë³¸ê°’ì€ '\n\n')ì—ì„œë§Œ ë¶„í• ë¨
- chunk_sizeëŠ” ë¶„í• ì´ ê°€ëŠ¥í•œ ê²½ìš° ë¶„í• í•  ìµœëŒ€ ì²­í¬ í¬ê¸°
- ë¬¸ìì—´ì´ nê°œì˜ ë¬¸ìë¡œ ì‹œì‘í•˜ê³ , êµ¬ë¶„ ê¸°í˜¸ê°€ ìˆìœ¼ë©°, ë‹¤ìŒ êµ¬ë¶„ ê¸°í˜¸ ì•ì— mê°œì˜ ë¬¸ìê°€ ë” ìˆëŠ” ê²½ìš° ì²« ë²ˆì§¸ ì²­í¬ í¬ê¸°ëŠ” chunk_size < n + m + len(separator)ì´ë©´ nì´ ë¨

ğŸŒˆ **Example**

**Case1**

```python
from langchain.text_splitter import CharacterTextSplitter

# "\n\n"ë¥¼ êµ¬ë¶„ìë¡œ ì„¤ì •í•˜ì—¬ í…ìŠ¤íŠ¸ë¥¼ ë¶„í• 
splitter = CharacterTextSplitter(
    separator=r"\n\n",
    is_separator_regex=True,
    chunk_size=12,
    chunk_overlap=0,
)

# ì˜ˆì œ í…ìŠ¤íŠ¸ ì„¤ì •
text = """Part 1, Chapter 1\n\nPart One\n\n1\n\nIt was a bright cold day in April, and the clocks were striking thirteen. Winston Smith, his chin nuzzled into his"""

# í…ìŠ¤íŠ¸ ë¶„í•  ìˆ˜í–‰
split_texts = splitter.split_text(text)

# ë¶„í• ëœ ì²­í¬ì˜ ìˆ˜ ì¶œë ¥
print(len(split_texts))

# ë¶„í• ëœ ì²­í¬ ì¶œë ¥
for i, chunk in enumerate(split_texts):
    print(f"Chunk {i + 1}:\n{chunk}\n")
```

```
Created a chunk of size 17, which is longer than the specified 12
4
Chunk 1:
Part 1, Chapter 1

Chunk 2:
Part One

Chunk 3:
1

Chunk 4:
It was a bright cold day in April, and the clocks were striking thirteen. Winston Smith, his chin nuzzled into his
```

- chunk_size (12) < n+m+len(sep) (13) â˜ True
  - n: 8 (Part One)
  - m: 1 (1)
  - len(sep): 4
- chunk_sizeê°€ nê¹Œì§€

**Case2**

```python
splitter = CharacterTextSplitter(
    separator=r"\n\n",
    is_separator_regex=True,
    chunk_size=13,
    chunk_overlap=0,
)

# í…ìŠ¤íŠ¸ ë¶„í•  ìˆ˜í–‰
split_texts = splitter.split_text(text)

# ë¶„í• ëœ ì²­í¬ì˜ ìˆ˜ ì¶œë ¥
print(len(split_texts))

# ë¶„í• ëœ ì²­í¬ ì¶œë ¥
for i, chunk in enumerate(split_texts):
    print(f"Chunk {i + 1}:\n{chunk}\n")
```

```
Created a chunk of size 17, which is longer than the specified 13
3
Chunk 1:
Part 1, Chapter 1

Chunk 2:
Part One\n\n1

Chunk 3:
It was a bright cold day in April, and the clocks were striking thirteen. Winston Smith, his chin nuzzled into his
```

- chunk_size (13) < n+m+len(sep) (13) â˜ false
  - n: 8 (Part One)
  - m: 1 (1)
  - len(sep): 4
- chunk_sizeê°€ nì´ ì•„ë‹ˆë¼ ë‹¤ìŒ ë¶„í•  ê¹Œì§€ í¬í•¨ (êµ¬ë¶„ìë„ í¬í•¨ë¨)

### 6.2 Tiktoken

ğŸ–¥ï¸ [OpenAI Tokenizer](https://platform.openai.com/tokenizer)

ğŸ“ **tiktoken**

> Text splitter that uses tiktoken encoder to count length. made by openAI

- OpenAIì˜ í† í¬ë‚˜ì´ì €ë¡œ ë¶„í• í•˜ê¸°ì— ëª¨ë¸ê³¼ lanchain ë‚´ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¹´ìš´íŒ…í•˜ëŠ” ë°©ë²•ì´ ì¼ì¹˜í•˜ê²Œ ë¨

### 6.3 Vectors

ğŸ–¥ï¸ [Word to Vec](https://turbomaze.github.io/word2vecjson/)

### 6.4 Vector Store

ğŸ“Œ **embed_queryì˜ ê³¼ì •**

- Step1. í† í°í™” â˜ tiktoken
- Step2. ì„ë² ë”© â˜ model api
- Step3. ì§‘ê³„ â˜ ë²¡í„° í‰ê· ì˜ ì •ê·œí™”

ğŸ“ **vectorstore**

> ë²¡í„° ê³µê°„ì—ì„œ ê²€ìƒ‰ì„ í•  ìˆ˜ ìˆê²Œ í•˜ëŠ” ë°ì´í„° ë² ì´ìŠ¤

ğŸ“ **LocalFileStore**

> BaseStore interface that works on the local file system.

ğŸ“ **CacheBackedEmbeddings**

> Interface for caching results from embedding models.

- from_bytes_store: ìºì‹œì— ì„ë² ë”©ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸í•˜ê³ 
  - ì—†ë‹¤ë©´ openai embedding
  - ìˆë‹¤ë©´ cached embedding (vector store)

### 6.5 Langsmith

ğŸ‘€ **Langsmith**

> api ì‚¬ìš© ë¶„ì„

```
LANGCHAIN_TRACING_V2=true
LANGCHAIN_ENDPOINT='https://api.smith.langchain.com'
LANGCHAIN_API_KEY='API_KEY'
```
