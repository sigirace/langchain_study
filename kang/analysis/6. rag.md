## RAG

### 6.1 Data Loaders and Splitters

📜 [공식문서-Retrival](https://python.langchain.com/v0.1/docs/modules/data_connection/)

📍 **UnstructureFileLoader**

- 다양한 파일들을 가져올 수 있음
- pdf, docx, excel, html ... even ppt!

📌 **loader의 output**

```python
print(loader.load())
print(len(loader.load()))
```

```
[Document(page_content='~~~~~')]
1
```

- Document 객체의 List인데 하나로 모두 포함되어 있음
  ☞ text를 나누어줘야 할 필요가 있음

👀 **chunk**

- chunk: 문서가 나누어진 단위
- chunk_size: 글자 수
  - chunk_size를 측정하는 기본적인 방법은 python의 len function

📍 **RecursiveCharacterTextSplitter**

- 문장 끝이나 문단의 끝부분마다 끊어줌
- 문장 중간에서 짤려 의미를 잃어버리는 것을 방지
- _parameters_
  - chunk_size: 문단의 사이즈
  - chunk_overlap: 앞 조각의 끝을 조금 가져와 문장을 연결시킴

📍 **CharacterTextSplitter**

- _parameters_
  - chunk_size, chunk_overlap
  - splitter: 문단을 splite

⛔️ **CharacterTextSplitter는 내 생각과 다르게 분할한다!**

📜 [Stackoverflow CharacterTextSplitter](https://stackoverflow.com/questions/76633836/what-does-langchain-charactertextsplitters-chunk-size-param-even-do)

- CharacterTextSplitter는 구분 기호(기본값은 '\n\n')에서만 분할됨
- chunk_size는 분할이 가능한 경우 분할할 최대 청크 크기
- 문자열이 n개의 문자로 시작하고, 구분 기호가 있으며, 다음 구분 기호 앞에 m개의 문자가 더 있는 경우 첫 번째 청크 크기는 chunk_size < n + m + len(separator)이면 n이 됨

🌈 **Example**

**Case1**

```python
from langchain.text_splitter import CharacterTextSplitter

# "\n\n"를 구분자로 설정하여 텍스트를 분할
splitter = CharacterTextSplitter(
    separator=r"\n\n",
    is_separator_regex=True,
    chunk_size=12,
    chunk_overlap=0,
)

# 예제 텍스트 설정
text = """Part 1, Chapter 1\n\nPart One\n\n1\n\nIt was a bright cold day in April, and the clocks were striking thirteen. Winston Smith, his chin nuzzled into his"""

# 텍스트 분할 수행
split_texts = splitter.split_text(text)

# 분할된 청크의 수 출력
print(len(split_texts))

# 분할된 청크 출력
for i, chunk in enumerate(split_texts):
    print(f"Chunk {i + 1}:\n{chunk}\n")
```

```
Created a chunk of size 17, which is longer than the specified 12
4
Chunk 1:
Part 1, Chapter 1

Chunk 2:
Part One

Chunk 3:
1

Chunk 4:
It was a bright cold day in April, and the clocks were striking thirteen. Winston Smith, his chin nuzzled into his
```

- chunk_size (12) < n+m+len(sep) (13) ☞ True
  - n: 8 (Part One)
  - m: 1 (1)
  - len(sep): 4
- chunk_size가 n까지

**Case2**

```python
splitter = CharacterTextSplitter(
    separator=r"\n\n",
    is_separator_regex=True,
    chunk_size=13,
    chunk_overlap=0,
)

# 텍스트 분할 수행
split_texts = splitter.split_text(text)

# 분할된 청크의 수 출력
print(len(split_texts))

# 분할된 청크 출력
for i, chunk in enumerate(split_texts):
    print(f"Chunk {i + 1}:\n{chunk}\n")
```

```
Created a chunk of size 17, which is longer than the specified 13
3
Chunk 1:
Part 1, Chapter 1

Chunk 2:
Part One\n\n1

Chunk 3:
It was a bright cold day in April, and the clocks were striking thirteen. Winston Smith, his chin nuzzled into his
```

- chunk_size (13) < n+m+len(sep) (13) ☞ false
  - n: 8 (Part One)
  - m: 1 (1)
  - len(sep): 4
- chunk_size가 n이 아니라 다음 분할 까지 포함 (구분자도 포함됨)

### 6.2 Tiktoken

🖥️ [OpenAI Tokenizer](https://platform.openai.com/tokenizer)

📍 **tiktoken**

> Text splitter that uses tiktoken encoder to count length. made by openAI

- OpenAI의 토크나이저로 분할하기에 모델과 lanchain 내에서 텍스트를 카운팅하는 방법이 일치하게 됨

### 6.3 Vectors

🖥️ [Word to Vec](https://turbomaze.github.io/word2vecjson/)

### 6.4 Vector Store

📌 **embed_query의 과정**

- Step1. 토큰화 ☞ tiktoken
- Step2. 임베딩 ☞ model api
- Step3. 집계 ☞ 벡터 평균의 정규화

📍 **vectorstore**

> 벡터 공간에서 검색을 할 수 있게 하는 데이터 베이스

📍 **LocalFileStore**

> BaseStore interface that works on the local file system.

📍 **CacheBackedEmbeddings**

> Interface for caching results from embedding models.

- from_bytes_store: 캐시에 임베딩이 존재하는지 확인하고
  - 없다면 openai embedding
  - 있다면 cached embedding (vector store)

### 6.5 Langsmith

👀 **Langsmith**

> api 사용 분석

```
LANGCHAIN_TRACING_V2=true
LANGCHAIN_ENDPOINT='https://api.smith.langchain.com'
LANGCHAIN_API_KEY='API_KEY'
```

### 6.6 RetrievalQA

📍 **RetrievalQA**

> Chain for question-answering against an index

- LLM chain과 같은 legacy한 chain
- 내부에 chain이 구현되어 있음
- _parameters_
  - llm: model
  - chain_type: QA chain type ☞ 추후설명
  - retriver
    - retriever는 interface
    - 구조화 되지 않은 query(자연어 질의)를 해석하여 document를 반환
    - vector store같은 저장 기능이 필요하지 않으며 단지 반환하는 역할만 하면 됨
    - vectorstore ☞ retriever

📍 **RetrievalQA chain_type**

**1. Stuff**

> 모든 document를 prompt에 채워(stuff) 넣는 것

- 📜 [공식문서 Stuff](https://js.langchain.com/v0.1/docs/modules/chains/document/stuff/)

**2. Refine**

> 문서를 하나씩 질문하여 얻은 답을 다시 질문으로 넣는 과정을 반복하며 질문을 개선(refine) 시킴

- 📜 [공식문서 Refine](https://js.langchain.com/v0.1/docs/modules/chains/document/refine/)

**3. MapReduce**

> 문서 하나하나를 요약하여 최종 프롬프트를 구성하고 이를 최종 질문으로 전달

- 📜 [공식문서 MapReduce](https://js.langchain.com/v0.1/docs/modules/chains/document/map_reduce/)

### 6.8 Stuff LCEL Chain

- LCEL의 prompt 부분에 모든 문서를 전달 ☞ stuff

📌 **Retriver LCEL**

- first chain: retriever는 document list를 반환하고 이는 String
- middle cahin: String은 propmt template으로 인해 propmt value를 가짐
- last cahin: prompt로 llm 수행
